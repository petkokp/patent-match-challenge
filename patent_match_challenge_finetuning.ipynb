{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent Match Challenge\n",
    "\n",
    "## Dimitrije Zdrale, Clement Marie, Petko Petkov\n",
    "\n",
    "This notebook is structured to handle patent similarity and re-ranking experiments using various transformer-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - pre-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petko/projects/patent-match-challenge/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Transformers and Torch loaded.\n",
      "Downloading NLTK data (if necessary)...\n",
      "Downloading NLTK package 'wordnet'...\n",
      "NLTK package 'wordnet' downloaded.\n",
      "NLTK check complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import os\n",
    "import scipy.sparse\n",
    "\n",
    "import hashlib, os, json, pickle, time, warnings, inspect, functools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    print(\"Sentence Transformers and Torch loaded.\")\n",
    "    SENTENCE_TRANSFORMERS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: Sentence Transformers or Torch not found. Dense embedding methods will be skipped.\")\n",
    "    print(\"Install them (`pip install sentence-transformers torch`) to enable.\")\n",
    "    SENTENCE_TRANSFORMERS_AVAILABLE = False\n",
    "\n",
    "print(\"Downloading NLTK data (if necessary)...\")\n",
    "nltk_packages = ['wordnet', 'stopwords', 'punkt']\n",
    "for package in nltk_packages:\n",
    "    try:\n",
    "        if package == 'punkt':\n",
    "            nltk.data.find(f'tokenizers/{package}')\n",
    "        else:\n",
    "             nltk.data.find(f'corpora/{package}')\n",
    "    except:\n",
    "        try:\n",
    "           print(f\"Downloading NLTK package '{package}'...\")\n",
    "           nltk.download(package, quiet=True)\n",
    "           print(f\"NLTK package '{package}' downloaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading NLTK package '{package}': {e}\")\n",
    "print(\"NLTK check complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing function performs several steps to clean and normalize text data:\n",
    "\n",
    "- Converts text to lowercase.\n",
    "- Removes punctuation, digits, and isolated single letters.\n",
    "- Normalizes whitespace.\n",
    "- Tokenizes text using NLTK.\n",
    "- Removes stopwords, using either standard NLTK stopwords or an extended set including domain-specific terms.\n",
    "- Applies lemmatization by default, with optional stemming if specified (`use_stemming=True`).\n",
    "- Filters out short tokens (less than 3 characters).\n",
    "\n",
    "This setup is designed to prepare technical or patent-like text for downstream NLP tasks by reducing noise and focusing on meaningful terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "custom_stopwords = set([\n",
    "    'claim', 'claims', 'claimed', 'method', 'system', 'device', 'apparatus', 'assembly', 'unit',\n",
    "    'comprising', 'comprises', 'thereof', 'wherein', 'said', 'thereby', 'herein', 'accordance',\n",
    "    'invention', 'present', 'related', 'relates', 'figure', 'fig', 'example', 'examples',\n",
    "    'embodiment', 'embodiments', 'accordance', 'therein', 'associated', 'provided', 'configured',\n",
    "    'includes', 'including', 'based', 'least', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten',\n",
    "    'first', 'second', 'third', 'fourth', 'fifth', 'etc', 'eg', 'ie',\n",
    "    'may', 'further', 'also', 'within', 'upon', 'used', 'using', 'use', 'capable', 'adapted',\n",
    "    'generally', 'typically', 'respectively', 'particularly', 'preferably', 'various', 'such',\n",
    "    'described', 'disclosed', 'illustrated', 'shown',\n",
    "    'portion', 'member', 'element', 'surface', 'axis', 'position', 'direction', 'side', 'end', 'top', 'bottom',\n",
    "    'lower', 'upper', 'inner', 'outer', 'rear', 'front', 'lateral',\n",
    "    'set', 'provide', 'generate', 'control', 'controlling', 'operation', 'value', 'signal', 'process', 'data',\n",
    "    'group', 'range', 'level', 'time', 'number', 'result', 'type', 'form', 'part', 'manner', 'step'\n",
    "])\n",
    "all_stopwords = stop_words.union(custom_stopwords)\n",
    "\n",
    "\n",
    "def preprocess_text(text, use_stemming=False, use_custom_stopwords=True):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text) # Remove single letters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Normalize whitespace\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    current_stopwords = all_stopwords if use_custom_stopwords else stop_words\n",
    "\n",
    "    if use_stemming:\n",
    "        processed_tokens = [stemmer.stem(word) for word in tokens if word not in current_stopwords and len(word) > 2]\n",
    "    else:\n",
    "        processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in current_stopwords and len(word) > 2]\n",
    "\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `create_corpus` helper function so we can extract and preprocess the data. It extracts and optionally preprocesses textual content from a structured corpus:\n",
    "- Supports multiple `text_type` options: `'title'`, `'abstract'`, `'claim1'`, `'claims'`, `'description'`, `'fulltext'`, or combinations like `'title_abstract'`.\n",
    "- Skips documents with missing identifiers or required text sections.\n",
    "- Optionally applies text preprocessing (e.g., lemmatization/stemming, stopword removal) unless `config['method'] == 'dense'`.\n",
    "- Tracks and reports the number of documents skipped.\n",
    "- Returns a list of dictionaries with `'id'` and `'text'` keys for each valid document.\n",
    "\n",
    "This function is designed to flexibly extract and clean specific sections of patent documents for downstream analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "            contents = json.load(file)\n",
    "        return contents\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "DATASETS_DIR = Path(\"./datasets\")\n",
    "\n",
    "def load_all():\n",
    "    content = DATASETS_DIR / \"Content_JSONs\"\n",
    "    citing_train = load_json_data(content/\"Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TRAIN.json\")\n",
    "    citing_test  = load_json_data(content/\"Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TEST.json\")\n",
    "    nonciting    = load_json_data(content/\"Cited_2020_Uncited_2010-2019_Cleaned_Content_22k/CLEANED_CONTENT_DATASET_cited_patents_by_2020_uncited_2010-2019.json\")\n",
    "    mapping      = pd.DataFrame(load_json_data(DATASETS_DIR/\"Citation_JSONs/Citation_Train.json\"))\n",
    "    return citing_train, citing_test, nonciting, mapping\n",
    "\n",
    "def add_query_prefix(text):\n",
    "    # Ensure text is a string\n",
    "    if not isinstance(text, str):\n",
    "            text = str(text) # Basic conversion if not string\n",
    "    return f\"query: {text}\"\n",
    "\n",
    "def add_passage_prefix(text):\n",
    "    # Ensure text is a string\n",
    "    if not isinstance(text, str):\n",
    "            text = str(text) # Basic conversion if not string\n",
    "    return f\"passage: {text}\"\n",
    "\n",
    "TEXT_PARTS = {\n",
    "    \"title\": [\"title\"],\n",
    "    \"abstract\": [\"pa01\"],\n",
    "    \"claim1\": [\"c-en-0001\"],\n",
    "    \"title_abstract_claims\": [\"title\", \"pa01\"] + [f\"c-en-{i:04d}\" for i in range(1, 101)]\n",
    "}\n",
    "\n",
    "def build_corpus(records: list[dict], text_type: str) -> tuple[list[str], list[str]]:\n",
    "    ids, texts = [], []\n",
    "    parts = TEXT_PARTS[text_type]\n",
    "    for rec in records:\n",
    "        doc_id = rec.get('Application_Number','') + rec.get('Application_Category','')\n",
    "        if not doc_id: continue\n",
    "        content = rec.get('Content', {})\n",
    "        segments = [content[k] for k in parts if content.get(k)]\n",
    "        if segments:\n",
    "            texts.append(' '.join(segments))\n",
    "            ids.append(doc_id)\n",
    "    return ids, texts\n",
    "\n",
    "def create_corpus(corpus, text_type, preprocess=False, config={}):\n",
    "    if not corpus:\n",
    "        print(f\"Warning: Attempting to create corpus from empty or None input for '{text_type}'.\")\n",
    "        return []\n",
    "\n",
    "    app_ids = []\n",
    "    texts = []\n",
    "    cnt = 0\n",
    "\n",
    "    print(f\"Creating corpus for text_type: '{text_type}'...\")\n",
    "\n",
    "    required_parts = []\n",
    "    if 'title' in text_type: required_parts.append('title')\n",
    "    if 'abstract' in text_type: required_parts.append('pa01')\n",
    "    if 'claim1' in text_type: required_parts.append('c-en-0001')\n",
    "\n",
    "    for doc in tqdm(corpus, desc=f\"Processing {text_type}\", leave=False):\n",
    "        doc_id = doc.get('Application_Number', '') + doc.get('Application_Category', '')\n",
    "        if not doc_id: # Skip if ID is missing\n",
    "            cnt+=1\n",
    "            continue\n",
    "        content = doc.get('Content', {})\n",
    "        if not content: # Skip if content is missing\n",
    "             cnt += 1\n",
    "             continue\n",
    "\n",
    "        doc_text_parts = []\n",
    "        missing_part = False\n",
    "\n",
    "        part_map = {\n",
    "            'title': ['title'],\n",
    "            'abstract': ['pa01'],\n",
    "            'claim1': ['c-en-0001'],\n",
    "            'claims': [k for k in content if k.startswith('c-en-')],\n",
    "            'description': [k for k in content if k.startswith('p')],\n",
    "            'fulltext': list(content.keys())\n",
    "        }\n",
    "\n",
    "        keys_to_extract = set()\n",
    "        if text_type == 'title_abstract': keys_to_extract.update(part_map['title'] + part_map['abstract'])\n",
    "        elif text_type == 'title_abstract_claim1': keys_to_extract.update(part_map['title'] + part_map['abstract'] + part_map['claim1'])\n",
    "        elif text_type == 'title_abstract_claims': keys_to_extract.update(part_map['title'] + part_map['abstract'] + part_map['claims'])\n",
    "        elif text_type in part_map: keys_to_extract.update(part_map[text_type])\n",
    "        else: print(f\"Warning: Unknown text_type '{text_type}' in create_corpus.\")\n",
    "\n",
    "        extracted_texts = [content.get(key) for key in keys_to_extract if content.get(key)]\n",
    "        doc_text_parts = list(dict.fromkeys(filter(None, extracted_texts)))\n",
    "\n",
    "        if text_type in ['title', 'abstract', 'claim1', 'claims', 'description']:\n",
    "             if not doc_text_parts:\n",
    "                 missing_part = True\n",
    "\n",
    "        # Final check and processing\n",
    "        if not doc_text_parts or missing_part:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            final_text = ' '.join(doc_text_parts)\n",
    "\n",
    "            # Apply preprocessing based on config and method type\n",
    "            if preprocess and config.get('method') != 'dense': # Only preprocess if requested AND method is not 'dense'\n",
    "                use_stemming_flag = config.get('use_stemming', False)\n",
    "                use_custom_stopwords_flag = config.get('use_custom_stopwords', True)\n",
    "                final_text = preprocess_text(final_text, use_stemming=use_stemming_flag, use_custom_stopwords=use_custom_stopwords_flag)\n",
    "\n",
    "            if not final_text or not final_text.strip():\n",
    "                 cnt += 1\n",
    "            else:\n",
    "                texts.append(final_text)\n",
    "                app_ids.append(doc_id)\n",
    "\n",
    "    if cnt > 0:\n",
    "         print(f\"Number of documents skipped (missing ID/Content or required text part for '{text_type}' or empty after preprocess): {cnt}\")\n",
    "         final_count = len(app_ids)\n",
    "         print(f\"Original corpus size: {len(corpus)}. Final corpus size: {final_count}\")\n",
    "         if final_count == 0:\n",
    "              print(f\"Warning: Resulting corpus for '{text_type}' is empty!\")\n",
    "\n",
    "    corpus_data = [{'id': app_id, 'text': text} for app_id, text in zip(app_ids, texts)]\n",
    "    return corpus_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate TF-IDF feature matrices for two sets of text data:\n",
    "- Concatenates `citing_texts` and `nonciting_texts` to fit the provided or default `TfidfVectorizer`.\n",
    "- Separately transforms the citing and non-citing texts into sparse TF-IDF matrices.\n",
    "- Prints progress updates and the resulting vocabulary size.\n",
    "- Returns three objects:\n",
    "  - `tfidf_matrix_citing`: TF-IDF matrix for citing documents.\n",
    "  - `tfidf_matrix_nonciting`: TF-IDF matrix for non-citing documents.\n",
    "  - `vectorizer`: The fitted TF-IDF vectorizer, which can be reused for other transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_matrix(\n",
    "    citing_texts,\n",
    "    nonciting_texts,\n",
    "    vectorizer: TfidfVectorizer = TfidfVectorizer(),\n",
    "    use_cache: bool = True,\n",
    "):\n",
    "    vectorizer.fit(nonciting_texts + citing_texts)\n",
    "    tfidf_matrix_citing = vectorizer.transform(citing_texts)\n",
    "    tfidf_matrix_nonciting = vectorizer.transform(nonciting_texts)\n",
    "\n",
    "    return tfidf_matrix_citing, tfidf_matrix_nonciting, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the BM25 ranking function for computing similarity between queries and documents:\n",
    "- **Initialization**: Accepts a matrix of vectorized documents (typically non-citing), along with BM25 parameters `k1` and `b`.\n",
    "- **`.fit()`**: \n",
    "  - Converts input to a CSR matrix if needed.\n",
    "  - Computes average document length and inverse document frequency (IDF) for each term.\n",
    "  - Ensures numerical stability with smoothing and clamping.\n",
    "- **`.predict()`**:\n",
    "  - Accepts a matrix of query vectors (typically citing documents).\n",
    "  - Calculates BM25 similarity scores between each query and all fitted documents.\n",
    "  - Uses the BM25 scoring formula in a vectorized fashion for efficiency.\n",
    "\n",
    "We generate BM25 similarity scores between citing and non-citing texts:\n",
    "- Fits a `CountVectorizer` on the combined corpus.\n",
    "- Transforms citing and non-citing texts into count matrices.\n",
    "- Initializes and fits the `BM25Score` model using the non-citing text matrix.\n",
    "- Computes and returns the BM25 similarity scores from citing to non-citing documents.\n",
    "- Also returns the fitted `vectorizer` and `bm25` model for reuse or inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Score:\n",
    "    def __init__(self, vectorized_docs, k1=1.5, b=0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.vectorized_docs = vectorized_docs\n",
    "\n",
    "    def fit(self, vectorized_queries=None, query_ids=None, args=None):\n",
    "        if not isinstance(self.vectorized_docs, scipy.sparse.csr_matrix):\n",
    "            try:\n",
    "                self.vectorized_docs = scipy.sparse.csr_matrix(self.vectorized_docs)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting BM25 input to CSR: {e}\")\n",
    "                raise\n",
    "\n",
    "        self.n_d = self.vectorized_docs.sum(axis=1).A\n",
    "        self.avgdl = np.mean(self.n_d)\n",
    "        if self.avgdl == 0:\n",
    "            print(\"Warning: Average document length is zero. Setting to 1.\")\n",
    "            self.avgdl = 1.0\n",
    "\n",
    "        self.n_docs = self.vectorized_docs.shape[0]\n",
    "        self.nq = np.array(self.vectorized_docs.getnnz(axis=0)).reshape(1,-1)\n",
    "        epsilon = 1e-9\n",
    "        self.idf = np.log(((self.n_docs - self.nq + 0.5) / (self.nq + 0.5 + epsilon)) + 1.0)\n",
    "        self.idf = np.maximum(self.idf, 0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, vectorized_queries):\n",
    "        if not isinstance(vectorized_queries, scipy.sparse.csr_matrix):\n",
    "            try:\n",
    "                vectorized_queries = scipy.sparse.csr_matrix(vectorized_queries)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting BM25 query input to CSR: {e}\")\n",
    "                raise\n",
    "\n",
    "        if vectorized_queries.shape[1] != self.vectorized_docs.shape[1]:\n",
    "             raise ValueError(f\"Query vector shape {vectorized_queries.shape} incompatible with document vector shape {self.vectorized_docs.shape}\")\n",
    "\n",
    "        idf = self.idf\n",
    "        term_freq_docs = self.vectorized_docs\n",
    "        term_freq_queries = vectorized_queries\n",
    "\n",
    "        doc_len_norm_factor = self.k1 * (1 - self.b + self.b * (self.n_d / self.avgdl))\n",
    "        k1_plus_1 = self.k1 + 1\n",
    "        denominator = term_freq_docs.copy().astype(np.float32)\n",
    "\n",
    "        denominator_dense = term_freq_docs.toarray() + doc_len_norm_factor\n",
    "        denominator_dense[denominator_dense == 0] = 1e-9\n",
    "\n",
    "        score_part_docs = term_freq_docs.multiply(k1_plus_1)\n",
    "        score_part_docs_dense = score_part_docs.toarray() / denominator_dense\n",
    "\n",
    "        weighted_scores = score_part_docs_dense * idf\n",
    "\n",
    "        query_term_presence = (term_freq_queries > 0).astype(np.float32)\n",
    "        final_scores = query_term_presence @ weighted_scores.T\n",
    "\n",
    "        return final_scores\n",
    "\n",
    "\n",
    "def create_bm25_matrix(\n",
    "    citing_texts,\n",
    "    nonciting_texts,\n",
    "    vectorizer: CountVectorizer = CountVectorizer(),\n",
    "    bm25_params: dict = None,\n",
    "    use_cache: bool = True,\n",
    "):\n",
    "    if bm25_params is None:\n",
    "        bm25_params = {\"k1\": 1.5, \"b\": 0.75}\n",
    "\n",
    "    vectorizer.fit(nonciting_texts + citing_texts)\n",
    "    count_matrix_citing = vectorizer.transform(citing_texts)\n",
    "    count_matrix_nonciting = vectorizer.transform(nonciting_texts)\n",
    "\n",
    "    bm25 = BM25Score(count_matrix_nonciting, **bm25_params).fit()\n",
    "    bm25_scores = bm25.predict(count_matrix_citing)\n",
    "\n",
    "    return bm25_scores, vectorizer, bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate dense vector embeddings for input texts using a Sentence Transformers model:\n",
    "- Loads a specified model (default: `multi-qa-mpnet-base-dot-v1`) on GPU if available.\n",
    "- Encodes text in batches to produce dense embeddings as NumPy arrays.\n",
    "- Handles errors related to model loading or inference.\n",
    "- Returns `None` if Sentence Transformers is not available or if encoding fails.\n",
    "\n",
    "We compute cosine similarity between two sets of dense embeddings:\n",
    "- Accepts NumPy arrays or PyTorch tensors for citing and non-citing embeddings.\n",
    "- Converts PyTorch tensors to NumPy arrays if needed.\n",
    "- Returns a similarity matrix where each row represents a citing document and each column a non-citing one.\n",
    "- Returns `None` if embeddings are missing or similarity calculation fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNE E5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% Block: Fine-tuning Setup\n",
    "# import os\n",
    "# import random\n",
    "# import math\n",
    "# from pathlib import Path\n",
    "# import json\n",
    "# from tqdm.auto import tqdm\n",
    "# import pandas as pd\n",
    "\n",
    "# try:\n",
    "#     import torch\n",
    "#     from torch.utils.data import DataLoader\n",
    "#     from sentence_transformers import SentenceTransformer, InputExample, losses, models, util as st_util\n",
    "#     from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "#     FINETUNE_OK = True\n",
    "# except ImportError:\n",
    "#     print(\"Error: sentence-transformers or torch not installed. Cannot perform fine-tuning.\")\n",
    "#     FINETUNE_OK = False\n",
    "\n",
    "# if FINETUNE_OK:\n",
    "#     # 1. Model Choice\n",
    "#     BASE_MODEL_NAME = \"intfloat/e5-large-v2\"\n",
    "#     FINETUNED_MODEL_PATH = Path(\"./fine_tuned_patent_model\")\n",
    "#     FINETUNED_MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "#     # 2. Data Configuration\n",
    "#     TEXT_TYPE_FINETUNE = \"title_abstract_claims\"\n",
    "\n",
    "#     # 3. Training Hyperparameters\n",
    "#     NUM_EPOCHS = 6\n",
    "#     TRAIN_BATCH_SIZE = 8\n",
    "#     EVAL_BATCH_SIZE = 16\n",
    "#     WARMUP_STEPS = 100\n",
    "#     LEARNING_RATE = 2e-5\n",
    "#     EVALUATION_STEPS = 500\n",
    "#     MAX_SEQ_LENGTH = 512\n",
    "#     USE_AMP = True\n",
    "\n",
    "#     # 4. Validation Set Split\n",
    "#     VALIDATION_SPLIT_FRACTION = 0.05\n",
    "#     SEED = 2025 # Make sure SEED is defined globally earlier\n",
    "\n",
    "#     # --- Ensure Core Data is Loaded ---\n",
    "#     try:\n",
    "#         # Check if necessary variables exist\n",
    "#         if 'CITING_TRAIN' not in locals() or 'NONCITING' not in locals() or 'MAP_DF' not in locals():\n",
    "#              print(\"Reloading data...\")\n",
    "#              CITING_TRAIN, _, NONCITING, MAP_DF = load_all() # Assuming load_all() is defined\n",
    "#         if 'build_corpus' not in locals():\n",
    "#              raise NameError(\"build_corpus function not defined.\")\n",
    "#     except NameError as e:\n",
    "#         print(f\"Error: Required data or function not found: {e}\")\n",
    "#         FINETUNE_OK = False # Prevent proceeding\n",
    "\n",
    "\n",
    "# if FINETUNE_OK:\n",
    "#     print(\"Preparing data for fine-tuning with prefixes...\")\n",
    "\n",
    "#     # --- Helper functions for prefixes ---\n",
    "#     def add_query_prefix(text):\n",
    "#         # Ensure text is a string\n",
    "#         if not isinstance(text, str):\n",
    "#              text = str(text) # Basic conversion if not string\n",
    "#         return f\"query: {text}\"\n",
    "\n",
    "#     def add_passage_prefix(text):\n",
    "#         # Ensure text is a string\n",
    "#         if not isinstance(text, str):\n",
    "#              text = str(text) # Basic conversion if not string\n",
    "#         return f\"passage: {text}\"\n",
    "\n",
    "#     # --- Build Text Maps (ID -> Text) - NO PREFIXES HERE ---\n",
    "#     print(\"Building text lookup maps...\")\n",
    "#     citing_text_map = {}\n",
    "#     # Assuming build_corpus is defined and accessible\n",
    "#     citing_ids_ft, citing_texts_ft = build_corpus(CITING_TRAIN, TEXT_TYPE_FINETUNE)\n",
    "#     for doc_id, text in zip(citing_ids_ft, citing_texts_ft):\n",
    "#         citing_text_map[doc_id] = text\n",
    "\n",
    "#     nonciting_text_map = {}\n",
    "#     nonciting_ids_ft, nonciting_texts_ft = build_corpus(NONCITING, TEXT_TYPE_FINETUNE)\n",
    "#     for doc_id, text in zip(nonciting_ids_ft, nonciting_texts_ft):\n",
    "#         nonciting_text_map[doc_id] = text\n",
    "#     print(f\"Built maps: {len(citing_text_map)} citing, {len(nonciting_text_map)} non-citing docs.\")\n",
    "\n",
    "\n",
    "#     # --- Create Positive Training Examples & Dev Set ---\n",
    "#     train_examples = []\n",
    "#     dev_queries = {} # {query_id: query_text_with_prefix}\n",
    "#     dev_corpus = {} # {doc_id: doc_text_with_prefix}\n",
    "#     dev_relevant_docs = {} # {query_id: set(relevant_doc_ids)}\n",
    "\n",
    "#     # Split citing patents into train and validation sets\n",
    "#     all_citing_ids = list(citing_text_map.keys())\n",
    "#     random.seed(SEED) # Use the global seed\n",
    "#     random.shuffle(all_citing_ids)\n",
    "#     split_idx = int(len(all_citing_ids) * (1 - VALIDATION_SPLIT_FRACTION))\n",
    "#     train_citing_ids = set(all_citing_ids[:split_idx])\n",
    "#     dev_citing_ids = set(all_citing_ids[split_idx:])\n",
    "\n",
    "#     print(f\"Split: {len(train_citing_ids)} train queries, {len(dev_citing_ids)} dev queries.\")\n",
    "\n",
    "#     processed_pairs = 0\n",
    "#     missing_texts = 0\n",
    "#     dev_positives_count = 0\n",
    "#     # Use MAP_DF for positive pairs\n",
    "#     for _, row in tqdm(MAP_DF.iterrows(), total=len(MAP_DF), desc=\"Processing citation pairs\"):\n",
    "#         # Make sure column indices/names match your MAP_DF structure\n",
    "#         citing_id = row[0]  # Assuming first column is citing ID\n",
    "#         cited_id = row[2]   # Assuming third column is cited ID\n",
    "\n",
    "#         query_text_orig = citing_text_map.get(citing_id)\n",
    "#         # Positive text can come from citing or non-citing corpus\n",
    "#         positive_text_orig = citing_text_map.get(cited_id)\n",
    "#         if not positive_text_orig:\n",
    "#             positive_text_orig = nonciting_text_map.get(cited_id)\n",
    "\n",
    "#         if query_text_orig and positive_text_orig:\n",
    "#             # <<< --- ADD PREFIXES HERE --- >>>\n",
    "#             prefixed_query = add_query_prefix(query_text_orig)\n",
    "#             prefixed_positive = add_passage_prefix(positive_text_orig)\n",
    "\n",
    "#             if citing_id in train_citing_ids:\n",
    "#                 # Use prefixed texts for InputExample\n",
    "#                 train_examples.append(InputExample(texts=[prefixed_query, prefixed_positive]))\n",
    "#                 processed_pairs += 1\n",
    "#             elif citing_id in dev_citing_ids:\n",
    "#                 # Prepare data for InformationRetrievalEvaluator using prefixed texts\n",
    "#                 if citing_id not in dev_queries:\n",
    "#                     dev_queries[citing_id] = prefixed_query # Store prefixed query\n",
    "#                 # Add positive doc to corpus and relevant docs (use prefixed text for corpus)\n",
    "#                 if cited_id not in dev_corpus:\n",
    "#                     dev_corpus[cited_id] = prefixed_positive # Store prefixed passage\n",
    "#                 dev_relevant_docs.setdefault(citing_id, set()).add(cited_id)\n",
    "#                 dev_positives_count += 1\n",
    "#         else:\n",
    "#             missing_texts += 1\n",
    "#             # Optional: Log which IDs were missing\n",
    "#             # if not query_text_orig: print(f\"Missing text for citing_id: {citing_id}\")\n",
    "#             # if not positive_text_orig: print(f\"Missing text for cited_id: {cited_id}\")\n",
    "\n",
    "\n",
    "#     print(f\"Created {len(train_examples)} training examples.\")\n",
    "#     print(f\"Prepared {len(dev_queries)} dev queries with {dev_positives_count} positive relations.\")\n",
    "#     if missing_texts > 0:\n",
    "#         print(f\"Warning: Skipped {missing_texts} pairs due to missing text for citing or cited patents.\")\n",
    "\n",
    "#     # --- Add Negative Examples to Dev Corpus (With Prefix) ---\n",
    "#     # We need some *non-relevant* documents in the dev corpus for the evaluator\n",
    "#     # Sample from NONCITING corpus.\n",
    "#     num_dev_negatives_needed = len(dev_corpus) * 5 # Aim for ~5x more negatives than positives\n",
    "#     dev_negatives_added = 0\n",
    "#     nonciting_ids_list = list(nonciting_text_map.keys())\n",
    "#     random.shuffle(nonciting_ids_list) # Shuffle to get random negatives\n",
    "\n",
    "#     for neg_id in nonciting_ids_list:\n",
    "#         if dev_negatives_added >= num_dev_negatives_needed:\n",
    "#             break\n",
    "#         if neg_id not in dev_corpus: # Avoid adding duplicates or existing positives\n",
    "#             neg_text = nonciting_text_map.get(neg_id)\n",
    "#             if neg_text: # Ensure text exists\n",
    "#                  # <<< --- ADD PREFIX HERE --- >>>\n",
    "#                  dev_corpus[neg_id] = add_passage_prefix(neg_text) # Add passage prefix\n",
    "#                  dev_negatives_added += 1\n",
    "\n",
    "#     print(f\"Added {dev_negatives_added} negative documents (passages) to the dev corpus.\")\n",
    "#     print(f\"Total dev corpus size: {len(dev_corpus)}\")\n",
    "\n",
    "#     # --- Sanity Check ---\n",
    "#     if not train_examples:\n",
    "#         print(\"Error: No training examples were created. Check data loading and matching.\")\n",
    "#         FINETUNE_OK = False\n",
    "#     if not dev_queries or not dev_corpus or not dev_relevant_docs:\n",
    "#         print(\"Error: Validation set data is incomplete. Check validation split and data processing.\")\n",
    "#         FINETUNE_OK = False\n",
    "#     # Check if any dev query ID has an empty relevant set (should not happen if processed correctly)\n",
    "#     for qid in dev_queries:\n",
    "#         if not dev_relevant_docs.get(qid):\n",
    "#              print(f\"Warning: Dev query {qid} has no relevant documents listed in dev_relevant_docs.\")\n",
    "\n",
    "\n",
    "# # %% Block: Model, Loss, and Evaluator Setup\n",
    "\n",
    "# if FINETUNE_OK:\n",
    "#     print(f\"Loading base model: {BASE_MODEL_NAME}\")\n",
    "#     # Option 1: Use a pre-trained model as is\n",
    "#     model = SentenceTransformer(BASE_MODEL_NAME)\n",
    "\n",
    "#     # Option 2: Add pooling layer if needed (e.g., if base is just transformer)\n",
    "#     # word_embedding_model = models.Transformer(BASE_MODEL_NAME, max_seq_length=MAX_SEQ_LENGTH)\n",
    "#     # pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "#     # model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "#     # Truncate long patent texts if they exceed model capacity\n",
    "#     model.max_seq_length = MAX_SEQ_LENGTH\n",
    "#     print(f\"Model max sequence length set to: {model.max_seq_length}\")\n",
    "\n",
    "#     # --- Loss Function ---\n",
    "#     # MultipleNegativesRankingLoss is recommended for training with (anchor, positive) pairs.\n",
    "#     # It uses other examples in the batch as negatives.\n",
    "#     loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "#     print(\"Using MultipleNegativesRankingLoss.\")\n",
    "\n",
    "#     # --- Dataloader ---\n",
    "#     # NoDuplicatesDataLoader ensures no duplicate texts are in the same batch,\n",
    "#     # useful for MNRL as it prevents trivial negative examples.\n",
    "#     train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n",
    "#     print(f\"Train dataloader created with batch size {TRAIN_BATCH_SIZE}.\")\n",
    "\n",
    "#     # --- Evaluator ---\n",
    "#     # Uses the prepared dev set components\n",
    "#     evaluator = InformationRetrievalEvaluator(\n",
    "#         queries=dev_queries,              # dict: {query_id: query_text}\n",
    "#         corpus=dev_corpus,                # dict: {doc_id: doc_text}\n",
    "#         relevant_docs=dev_relevant_docs,  # dict: {query_id: set(relevant_doc_ids)}\n",
    "#         batch_size=EVAL_BATCH_SIZE,\n",
    "#         main_score_function='cosine',     # How to compare embeddings\n",
    "#         score_functions={'cos_sim': st_util.cos_sim},\n",
    "#         name='patent_dev',\n",
    "#         show_progress_bar=True,\n",
    "#         write_csv=True,                   # Saves detailed eval results\n",
    "#     )\n",
    "#     print(\"InformationRetrievalEvaluator configured.\")\n",
    "\n",
    "\n",
    "# # %% Block: Training Execution\n",
    "\n",
    "# if FINETUNE_OK:\n",
    "#     print(\"\\n--- Starting Fine-Tuning Training ---\")\n",
    "\n",
    "#     # Calculate number of steps per epoch if needed for logging/scheduling\n",
    "#     steps_per_epoch = math.ceil(len(train_dataloader))\n",
    "#     print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "#     if EVALUATION_STEPS > steps_per_epoch:\n",
    "#         print(f\"Warning: EVALUATION_STEPS ({EVALUATION_STEPS}) > steps per epoch ({steps_per_epoch}). Evaluation will happen less than once per epoch.\")\n",
    "\n",
    "\n",
    "#     # --- Run Training ---\n",
    "#     model.fit(\n",
    "#         train_objectives=[(train_dataloader, loss)],\n",
    "#         evaluator=evaluator,\n",
    "#         epochs=NUM_EPOCHS,\n",
    "#         evaluation_steps=EVALUATION_STEPS, # Evaluate every N steps\n",
    "#         warmup_steps=WARMUP_STEPS,\n",
    "#         optimizer_params={'lr': LEARNING_RATE},\n",
    "#         output_path=str(FINETUNED_MODEL_PATH), # Save checkpoints here\n",
    "#         save_best_model=True,          # Save the model with the best MAP score on dev\n",
    "#         checkpoint_path=str(FINETUNED_MODEL_PATH / \"checkpoints\"),\n",
    "#         checkpoint_save_steps=EVALUATION_STEPS * 2, # Save checkpoints less frequently than eval\n",
    "#         checkpoint_save_total_limit=3, # Keep only last 3 checkpoints\n",
    "#         use_amp=USE_AMP,                 # Enable mixed precision\n",
    "#         show_progress_bar=True\n",
    "#     )\n",
    "\n",
    "#     print(f\"\\n--- Fine-tuning finished ---\")\n",
    "#     print(f\"Best model saved to: {FINETUNED_MODEL_PATH}\")\n",
    "\n",
    "#     # Optional: Load the best model immediately for use\n",
    "#     # print(\"Loading best fine-tuned model...\")\n",
    "#     # fine_tuned_model = SentenceTransformer(str(FINETUNED_MODEL_PATH))\n",
    "#     # Now you could potentially replace the model in your DenseIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.environ[\"HF_TOKEN\"] = \"YOUR_TOKEN\"\n",
    "\n",
    "# repo_name = \"e5-large-v2-patent\"\n",
    "# repo_id = f\"petkopetkov/{repo_name}\"\n",
    "\n",
    "# model_path = f\"{FINETUNED_MODEL_PATH}/checkpoints/checkpoint-2898\"\n",
    "\n",
    "# print(f\"Loading best model from: {model_path}\")\n",
    "# best_model = SentenceTransformer(str(model_path))\n",
    "\n",
    "# best_model.save_to_hub(\n",
    "#     repo_id=repo_id,\n",
    "# )\n",
    "# print(f\"âœ… Model successfully uploaded to: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_embeddings(\n",
    "    texts,\n",
    "    model_name: str = \"multi-qa-mpnet-base-dot-v1\",\n",
    "    batch_size: int = 64,\n",
    "):\n",
    "    if not SENTENCE_TRANSFORMERS_AVAILABLE:\n",
    "        print(\"Sentence Transformers not available. Skipping dense embeddings.\")\n",
    "        return None\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    emb = model.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True,\n",
    "        batch_size=batch_size,\n",
    "        normalize_embeddings=False,\n",
    "    )\n",
    "\n",
    "    return emb\n",
    "\n",
    "def calculate_dense_similarity(citing_embeddings, nonciting_embeddings):\n",
    "    if citing_embeddings is None or nonciting_embeddings is None:\n",
    "        print(\"Cannot calculate dense similarity due to missing embeddings.\")\n",
    "        return None\n",
    "    print(\"Calculating Dense Cosine Similarities...\")\n",
    "    if isinstance(citing_embeddings, torch.Tensor):\n",
    "        citing_embeddings = citing_embeddings.cpu().numpy()\n",
    "    if isinstance(nonciting_embeddings, torch.Tensor):\n",
    "        nonciting_embeddings = nonciting_embeddings.cpu().numpy()\n",
    "    try:\n",
    "        similarity_scores = cosine_similarity(citing_embeddings, nonciting_embeddings)\n",
    "        return similarity_scores\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating cosine similarity: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric Functions\n",
    "\n",
    "#### `get_true_and_predicted(citing_to_cited_dict, recommendations_dict)`\n",
    "Prepares ground truth and predicted labels for evaluation:\n",
    "- Matches citing document IDs from the recommendations with the mapping dictionary.\n",
    "- Returns:\n",
    "  - `true_labels`: list of cited document ID lists.\n",
    "  - `predicted_labels`: list of predicted document ID lists.\n",
    "  - `not_in_citation_mapping`: count of citing documents not found in the ground truth.\n",
    "\n",
    "#### `mean_recall_at_k(true_labels, predicted_labels, k=10)`\n",
    "Calculates the mean recall at cutoff rank `k`:\n",
    "- For each query, computes the fraction of relevant documents retrieved in the top-`k` predictions.\n",
    "- Returns the average recall across all queries.\n",
    "\n",
    "#### `mean_average_precision(true_labels, predicted_labels, k=10)`\n",
    "Computes Mean Average Precision (MAP) at rank `k`:\n",
    "- For each query, calculates precision at each relevant hit in the top-`k` predictions.\n",
    "- Averages these per-query precision values over all relevant documents.\n",
    "- Returns the mean of average precision scores across all queries.\n",
    "\n",
    "#### `mean_ranking(true_labels, predicted_labels)`\n",
    "Computes the average rank position of relevant documents:\n",
    "- For each query, determines the rank position of each relevant document in the predictions.\n",
    "- Returns the mean of these ranks across all queries.\n",
    "- Penalizes missed documents with the maximum possible rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_dict(mapping_df):\n",
    "    mapping_dict = {}\n",
    "    if not isinstance(mapping_df, pd.DataFrame) or mapping_df.shape[1] < 3:\n",
    "        print(\"Warning: mapping_df invalid in get_mapping_dict.\")\n",
    "        return mapping_dict\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        try:\n",
    "            key = row.iloc[0]\n",
    "            value = row.iloc[2]\n",
    "            if key in mapping_dict:\n",
    "                mapping_dict[key].append(value)\n",
    "            else:\n",
    "                mapping_dict[key] = [value]\n",
    "        except IndexError:\n",
    "            print(f\"Warning: Index error in mapping_df row: {row}\")\n",
    "            continue\n",
    "    return mapping_dict\n",
    "\n",
    "def get_true_and_predicted(citing_to_cited_dict, recommendations_dict):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    not_in_citation_mapping = 0\n",
    "    if not recommendations_dict: return [], [], 0\n",
    "    for citing_id in recommendations_dict.keys():\n",
    "        if citing_id in citing_to_cited_dict:\n",
    "            true_labels.append(citing_to_cited_dict[citing_id])\n",
    "            prediction = recommendations_dict[citing_id]\n",
    "            predicted_labels.append(prediction if isinstance(prediction, list) else [])\n",
    "        else:\n",
    "            not_in_citation_mapping += 1\n",
    "    return true_labels, predicted_labels, not_in_citation_mapping\n",
    "\n",
    "def mean_recall_at_k(true_labels, predicted_labels, k=10):\n",
    "    recalls_at_k = []\n",
    "    if not true_labels or not predicted_labels: return 0.0\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        if not isinstance(true, (list, set)) or not isinstance(pred, list): continue\n",
    "        true_set = set(true)\n",
    "        if not true_set: continue\n",
    "        actual_k = min(k, len(pred))\n",
    "        relevant_count = sum(1 for item in pred[:actual_k] if item in true_set)\n",
    "        recall = relevant_count / len(true_set)\n",
    "        recalls_at_k.append(recall)\n",
    "    mean_recall = sum(recalls_at_k) / len(recalls_at_k) if recalls_at_k else 0\n",
    "    return mean_recall\n",
    "\n",
    "def mean_average_precision(true_labels, predicted_labels, k=10):\n",
    "    average_precisions = []\n",
    "    if not true_labels or not predicted_labels: return 0.0\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        if not isinstance(true, (list, set)) or not isinstance(pred, list): continue\n",
    "        true_set = set(true)\n",
    "        if not true_set: continue\n",
    "        precision_at_k = []\n",
    "        relevant_count = 0\n",
    "        actual_k = min(k, len(pred))\n",
    "        for i, item in enumerate(pred[:actual_k]):\n",
    "            if item in true_set:\n",
    "                relevant_count += 1\n",
    "                precision_at_k.append(relevant_count / (i + 1))\n",
    "        average_precision = sum(precision_at_k) / len(true_set)\n",
    "        average_precisions.append(average_precision)\n",
    "    mean_average_precision_val = sum(average_precisions) / len(average_precisions) if average_precisions else 0\n",
    "    return mean_average_precision_val\n",
    "\n",
    "def mean_ranking(true_labels, predicted_labels):\n",
    "    mean_ranks = []\n",
    "    if not true_labels or not predicted_labels: return float('inf')\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        if not isinstance(true, (list, set)) or not isinstance(pred, list): continue\n",
    "        if not true: continue\n",
    "        ranks = []\n",
    "        pred_list = list(pred)\n",
    "        max_rank = len(pred_list) + 1\n",
    "        for item in true:\n",
    "            try:\n",
    "                rank = pred_list.index(item) + 1\n",
    "            except ValueError:\n",
    "                rank = max_rank\n",
    "            ranks.append(rank)\n",
    "        mean_rank = sum(ranks) / len(ranks) if ranks else max_rank\n",
    "        mean_ranks.append(mean_rank)\n",
    "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else float('inf')\n",
    "    return mean_of_mean_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate top-`k` ranked recommendations for each citing document based on similarity scores:\n",
    "- Validates input dimensions and handles errors gracefully.\n",
    "- Converts sparse or non-array score types to NumPy arrays.\n",
    "- Sorts scores in descending order and retrieves top-`k` non-citing document IDs for each citing document.\n",
    "- Returns a dictionary: `{citing_id: [top_k_nonciting_ids]}`.\n",
    "\n",
    "We combine multiple ranking outputs using **Reciprocal Rank Fusion (RRF)**:\n",
    "- Requires at least two ranking dictionaries with overlapping query IDs.\n",
    "- Computes a combined score for each document using the formula: `1 / (k + rank)`.\n",
    "- Sorts documents per query by descending fused score.\n",
    "- Returns a new dictionary with combined rankings: `{query_id: [ranked_doc_ids]}`.\n",
    "\n",
    "RRF is useful for aggregating rankings from multiple models or similarity measures, enhancing diversity and robustness of final recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_ranks(citing_corpus_data, nonciting_corpus_data, similarity_scores, k=10):\n",
    "    top_k_results = {}\n",
    "    if similarity_scores is None or not citing_corpus_data or not nonciting_corpus_data:\n",
    "        print(\"Warning: Cannot generate ranks due to missing scores or corpus data.\")\n",
    "        return top_k_results\n",
    "\n",
    "    num_citing = similarity_scores.shape[0]\n",
    "    num_nonciting = len(nonciting_corpus_data)\n",
    "\n",
    "    if num_citing != len(citing_corpus_data):\n",
    "         print(f\"Warning: Citing scores ({num_citing}) != citing corpus ({len(citing_corpus_data)}). Adjusting...\")\n",
    "         num_citing = min(num_citing, len(citing_corpus_data))\n",
    "\n",
    "    if similarity_scores.shape[1] != num_nonciting:\n",
    "        print(f\"Warning: Similarity score columns ({similarity_scores.shape[1]}) != non-citing docs ({num_nonciting}). Cannot rank.\")\n",
    "        return {}\n",
    "\n",
    "    actual_k = min(k, num_nonciting)\n",
    "    print(f\"Generating top {actual_k} ranks...\")\n",
    "    for i in tqdm(range(num_citing), desc=\"Ranking\", leave=False):\n",
    "        try:\n",
    "            citing_id = citing_corpus_data[i]['id']\n",
    "            patent_scores = similarity_scores[i]\n",
    "            if isinstance(patent_scores, (np.matrix, scipy.sparse.spmatrix)):\n",
    "                patent_scores = patent_scores.toarray().flatten()\n",
    "            elif not isinstance(patent_scores, np.ndarray):\n",
    "                 patent_scores = np.array(patent_scores)\n",
    "\n",
    "            if patent_scores.ndim != 1 or len(patent_scores) != num_nonciting:\n",
    "                 print(f\"Warning: Skipping citing ID {citing_id} due to score shape/length mismatch.\")\n",
    "                 continue\n",
    "\n",
    "            top_indices = np.argsort(-patent_scores)[:actual_k] # Negate scores\n",
    "            top_nonciting_ids = [nonciting_corpus_data[j]['id'] for j in top_indices if j < num_nonciting]\n",
    "            top_k_results[citing_id] = top_nonciting_ids\n",
    "        except IndexError as e:\n",
    "            print(f\"Warning: Index error processing citing item {i} (ID: {citing_corpus_data[i].get('id', 'N/A')}). Skipping. Error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Unexpected error processing citing item {i} (ID: {citing_corpus_data[i].get('id', 'N/A')}): {e}. Skipping.\")\n",
    "    return top_k_results\n",
    "\n",
    "\n",
    "def combine_rankings_rrf(rank_dict_list, k_rrf=60):\n",
    "    print(f\"Combining {len(rank_dict_list)} rankings using RRF (k={k_rrf})...\")\n",
    "    if not rank_dict_list or len(rank_dict_list) < 2:\n",
    "        print(\"Warning: Need at least two ranking lists for RRF.\")\n",
    "        return rank_dict_list[0] if rank_dict_list else {}\n",
    "\n",
    "    query_ids = set(rank_dict_list[0].keys())\n",
    "    for r_dict in rank_dict_list[1:]:\n",
    "        query_ids.intersection_update(r_dict.keys())\n",
    "    if not query_ids:\n",
    "        print(\"Warning: No common query IDs found among ranking lists for RRF.\")\n",
    "        return {}\n",
    "\n",
    "    combined_scores = {query_id: {} for query_id in query_ids}\n",
    "    print(f\"Processing {len(query_ids)} common queries for RRF.\")\n",
    "\n",
    "    for ranks_dict in tqdm(rank_dict_list, desc=\"Processing Rank Lists\", leave=False):\n",
    "        for query_id in query_ids:\n",
    "            ranked_docs = ranks_dict.get(query_id, [])\n",
    "            for rank, doc_id in enumerate(ranked_docs):\n",
    "                rank_score = 1.0 / (k_rrf + rank + 1)\n",
    "                combined_scores[query_id][doc_id] = combined_scores[query_id].get(doc_id, 0) + rank_score\n",
    "\n",
    "    final_rankings = {}\n",
    "    for query_id, doc_scores in tqdm(combined_scores.items(), desc=\"Sorting RRF Results\", leave=False):\n",
    "        sorted_docs = sorted(doc_scores.items(), key=lambda item: (-item[1], item[0]))\n",
    "        final_rankings[query_id] = [doc_id for doc_id, score in sorted_docs]\n",
    "\n",
    "    return final_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process Overview**:\n",
    "  1. **Corpus Creation**: Extracts and optionally preprocesses texts for citing and non-citing documents.\n",
    "  2. **Similarity Calculation**:\n",
    "     - `tfidf`: Uses `TfidfVectorizer` and cosine similarity.\n",
    "     - `bm25`: Uses `CountVectorizer` and BM25 scoring.\n",
    "     - `dense`: Uses Sentence Transformers and cosine similarity on embeddings.\n",
    "  3. **Ranking**: Generates top-k ranked results for each citing document.\n",
    "  4. **RRF Preparation**: Stores rankings if needed for Reciprocal Rank Fusion (RRF).\n",
    "  5. **Evaluation**: Computes key metrics:\n",
    "     - `Recall@10`, `20`, `50`, `100`\n",
    "     - `MAP@100` (Mean Average Precision)\n",
    "     - `Mean Rank`\n",
    "     - Count of measured queries and those missing from the mapping\n",
    "\n",
    "- **Outputs**:\n",
    "  - `metrics`: Dictionary of evaluation metrics.\n",
    "  - `model_details_run`: Includes trained vectorizers/models and non-citing representation data (matrix or embeddings).\n",
    "\n",
    "- **Error Handling**:\n",
    "  - Skips experiments if corpora are empty or libraries are missing.\n",
    "  - Gracefully handles exceptions and prints tracebacks for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config, json_citing_train, json_nonciting, mapping_dict, k_eval=100):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n--- Running Experiment: {config['name']} ---\")\n",
    "\n",
    "    if config['method'] == 'dense' and not SENTENCE_TRANSFORMERS_AVAILABLE:\n",
    "        print(\"Skipping dense experiment as libraries are not available.\")\n",
    "        return None, None\n",
    "\n",
    "    print(\"Creating corpora...\")\n",
    "    citing_corpus = create_corpus(json_citing_train, config['text_type'], preprocess=config.get('preprocess', False), config=config)\n",
    "    nonciting_corpus = create_corpus(json_nonciting, config['text_type'], preprocess=config.get('preprocess', False), config=config)\n",
    "\n",
    "    if not citing_corpus or not nonciting_corpus:\n",
    "        print(\"Skipping experiment due to empty corpus.\")\n",
    "        return None, None\n",
    "\n",
    "    citing_texts = [doc['text'] for doc in citing_corpus]\n",
    "    nonciting_texts = [doc['text'] for doc in nonciting_corpus]\n",
    "\n",
    "    similarity_scores = None\n",
    "    fitted_vectorizer = None\n",
    "    fitted_bm25_model = None\n",
    "    nonciting_matrix_tfidf = None\n",
    "    nonciting_embeddings = None\n",
    "    model_details_run = {}\n",
    "\n",
    "    try:\n",
    "        if config['method'] == 'tfidf':\n",
    "            vectorizer = TfidfVectorizer(**config.get('vectorizer_params', {}))\n",
    "            tfidf_citing, tfidf_nonciting, fitted_vectorizer = create_tfidf_matrix(\n",
    "                citing_texts, nonciting_texts, vectorizer\n",
    "            )\n",
    "            print(\"Calculating Cosine Similarities...\")\n",
    "            similarity_scores = linear_kernel(tfidf_citing, tfidf_nonciting)\n",
    "            nonciting_matrix_tfidf = tfidf_nonciting\n",
    "\n",
    "        elif config['method'] == 'bm25':\n",
    "            vectorizer = CountVectorizer(**config.get('vectorizer_params', {}))\n",
    "            bm25_scores, fitted_vectorizer, fitted_bm25_model = create_bm25_matrix(\n",
    "                citing_texts, nonciting_texts, vectorizer, config.get('bm25_params', {})\n",
    "            )\n",
    "            similarity_scores = bm25_scores\n",
    "\n",
    "        elif config['method'] == 'dense':\n",
    "            model_name = config.get('embedding_model')\n",
    "            needs_prefix = model_name and (\"e5\" in model_name.lower())\n",
    "            \n",
    "            if needs_prefix:\n",
    "                print(f\"Applying E5 prefixes for model: {model_name}\")\n",
    "                prefixed_citing_texts = [add_query_prefix(text) for text in citing_texts]\n",
    "                prefixed_nonciting_texts = [add_passage_prefix(text) for text in nonciting_texts]\n",
    "            else:\n",
    "                prefixed_citing_texts = citing_texts\n",
    "                prefixed_nonciting_texts = nonciting_texts\n",
    "\n",
    "            print(\"Generating Dense Embeddings...\")\n",
    "            citing_embeddings = create_dense_embeddings(\n",
    "                prefixed_citing_texts,\n",
    "                model_name=config.get('embedding_model'),\n",
    "                batch_size=config.get('embedding_batch_size')\n",
    "            )\n",
    "            nonciting_embeddings = create_dense_embeddings(\n",
    "                prefixed_nonciting_texts,\n",
    "                model_name=config.get('embedding_model'),\n",
    "                batch_size=config.get('embedding_batch_size'),\n",
    "            )\n",
    "            if citing_embeddings is None or nonciting_embeddings is None:\n",
    "                 raise ValueError(\"Dense embedding generation failed.\")\n",
    "            similarity_scores = calculate_dense_similarity(citing_embeddings, nonciting_embeddings)\n",
    "            model_details_run['nonciting_embeddings'] = nonciting_embeddings # Store needed embeddings\n",
    "\n",
    "        else:\n",
    "            print(f\"Unknown method: {config['method']}\")\n",
    "            return None, None\n",
    "\n",
    "        if similarity_scores is None:\n",
    "            raise ValueError(\"Failed to compute similarity scores.\")\n",
    "\n",
    "        print(f\"Shape of similarity/scores matrix: {similarity_scores.shape}\")\n",
    "\n",
    "        full_rank = top_k_ranks(citing_corpus, nonciting_corpus, similarity_scores, k=len(nonciting_corpus))\n",
    "        \n",
    "        best_bm25_config_name_for_rrf = 'T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)'\n",
    "        best_dense_config_name_for_rrf = 'Dense (e5â€‘largeâ€‘v2-patent)'\n",
    "        best_mean_rank_bm25_config_name = 'T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)'\n",
    "\n",
    "        if config['name'] == best_bm25_config_name_for_rrf:\n",
    "            print(f\"Storing BM25 (Best MAP/Recall) ranks for RRF from {config['name']}...\")\n",
    "            global best_bm25_ranks_train\n",
    "            best_bm25_ranks_train = full_rank\n",
    "        elif config['name'] == best_dense_config_name_for_rrf:\n",
    "            print(f\"Storing Dense ranks for RRF from {config['name']}...\")\n",
    "            global best_dense_ranks_train\n",
    "            best_dense_ranks_train = full_rank\n",
    "        elif config['name'] == best_mean_rank_bm25_config_name:\n",
    "            print(f\"Storing BM25 (Best Mean Rank) ranks for RRF from {config['name']}...\")\n",
    "            global best_mean_rank_bm25_ranks_train\n",
    "            best_mean_rank_bm25_ranks_train = full_rank\n",
    "\n",
    "        top_k_rank_eval = {qid: ranks[:k_eval] for qid, ranks in full_rank.items()}\n",
    "        print(\"Calculating metrics...\")\n",
    "        true_labels, predicted_labels, not_in_mapping = get_true_and_predicted(mapping_dict, top_k_rank_eval)\n",
    "\n",
    "        if not predicted_labels:\n",
    "            print(\"No predictions generated for metric calculation.\")\n",
    "            metrics = {'recall@10': 0,'recall@20': 0,'recall@50': 0,'recall@100': 0, 'map@100': 0, 'mean_rank': float('inf'), 'num_measured': 0, 'not_in_mapping': not_in_mapping}\n",
    "        else:\n",
    "            metrics = {\n",
    "                'recall@10': mean_recall_at_k(true_labels, predicted_labels, k=10),\n",
    "                'recall@20': mean_recall_at_k(true_labels, predicted_labels, k=20),\n",
    "                'recall@50': mean_recall_at_k(true_labels, predicted_labels, k=50),\n",
    "                'recall@100': mean_recall_at_k(true_labels, predicted_labels, k=100),\n",
    "                'map@100': mean_average_precision(true_labels, predicted_labels, k=100),\n",
    "                'mean_rank': mean_ranking(true_labels, predicted_labels),\n",
    "                'num_measured': len(predicted_labels), 'not_in_mapping': not_in_mapping\n",
    "            }\n",
    "\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"Recall@100: {metrics['recall@100']:.4f}\")\n",
    "        print(f\"MAP@100: {metrics['map@100']:.4f}\")\n",
    "        print(f\"Mean Rank: {metrics['mean_rank']:.4f}\")\n",
    "\n",
    "        model_details_run.update({\n",
    "            'vectorizer': fitted_vectorizer, # None for dense\n",
    "            'bm25_model': fitted_bm25_model, # None for tfidf/dense\n",
    "            'nonciting_corpus': nonciting_corpus,\n",
    "            'nonciting_matrix': nonciting_matrix_tfidf, # None for bm25/dense\n",
    "            'nonciting_embeddings': model_details_run.get('nonciting_embeddings', None) # Added if dense\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during experiment '{config['name']}': {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Experiment '{config['name']}' completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    return metrics, model_details_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files Loaded**:\n",
    "  - `citing_TRAIN.json`: Citing documents (training set)\n",
    "  - `citing_TEST.json`: Citing documents (test set)\n",
    "  - `CLEANED_CONTENT_DATASET_cited...json`: Pool of non-citing documents\n",
    "  - `Citation_Train.json`: Mapping of citing-to-cited pairs\n",
    "- **Validation**: Ensures all files are loaded; exits if any are missing.\n",
    "- **Metadata Printed**:\n",
    "  - Document counts for each loaded dataset\n",
    "  - Size of generated citing-to-cited mapping dictionary (`mapping_dict`)\n",
    "\n",
    "#### **Experiment Setup**\n",
    "- **Configurations Defined**:\n",
    "  - Specifies multiple experiment configurations using various retrieval methods (`bm25`, `dense`)\n",
    "  - Each config includes relevant parameters (e.g., preprocessing flags, model/vectorizer details)\n",
    "- **Best Configs for RRF**:\n",
    "  - Named configs designated for Reciprocal Rank Fusion (RRF), based on prior performance:\n",
    "    - `best_bm25_config_name_for_rrf`\n",
    "    - `best_dense_config_name_for_rrf`\n",
    "    - `best_mean_rank_bm25_config_name`\n",
    "- **Dense Model Handling**:\n",
    "  - Dense configurations are removed if Sentence Transformers library is not available.\n",
    "- **Results Initialization**:\n",
    "  - Tracks best performance across configurations using recall@100, MAP@100, and stores top model configuration and details.\n",
    "- **Global Variables for RRF**:\n",
    "  - Prepares variables (`best_bm25_ranks_train`, etc.) to store rankings used in later rank fusion steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets...\n",
      "\n",
      "Datasets loaded successfully.\n",
      "Citing Train: 6831\n",
      "Citing Test: 1000\n",
      "Non-Citing Pool: 16837\n",
      "Training Citations Raw Pairs: 8594\n",
      "Training Citations Dict (Unique Citing Patents): 6831\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading datasets...\")\n",
    "DATA_DIR = \"./datasets\"\n",
    "content_path = os.path.join(DATA_DIR, \"Content_JSONs\")\n",
    "citation_path = os.path.join(DATA_DIR, \"Citation_JSONs\")\n",
    "path_citing_train = os.path.join(content_path, \"Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TRAIN.json\")\n",
    "path_citing_test = os.path.join(content_path, \"Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TEST.json\")\n",
    "path_nonciting = os.path.join(content_path, \"Cited_2020_Uncited_2010-2019_Cleaned_Content_22k/CLEANED_CONTENT_DATASET_cited_patents_by_2020_uncited_2010-2019.json\")\n",
    "path_citations = os.path.join(citation_path, \"Citation_Train.json\")\n",
    "\n",
    "json_citing_train = load_json_data(path_citing_train)\n",
    "json_citing_test = load_json_data(path_citing_test)\n",
    "json_nonciting = load_json_data(path_nonciting)\n",
    "json_citing_to_cited = load_json_data(path_citations)\n",
    "\n",
    "if not all([json_citing_train, json_citing_test, json_nonciting, json_citing_to_cited]):\n",
    "    print(\"\\nCritical Error: One or more dataset files failed to load. Please check paths. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nDatasets loaded successfully.\")\n",
    "print(f\"Citing Train: {len(json_citing_train)}\")\n",
    "print(f\"Citing Test: {len(json_citing_test)}\")\n",
    "print(f\"Non-Citing Pool: {len(json_nonciting)}\")\n",
    "print(f\"Training Citations Raw Pairs: {len(json_citing_to_cited)}\")\n",
    "\n",
    "mapping_dataset_df = pd.DataFrame(json_citing_to_cited)\n",
    "mapping_dict = get_mapping_dict(mapping_dataset_df)\n",
    "print(f\"Training Citations Dict (Unique Citing Patents): {len(mapping_dict)}\")\n",
    "\n",
    "# Define base names for RRF components FIRST\n",
    "best_bm25_config_name_for_rrf = 'T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)'\n",
    "best_dense_config_name_for_rrf = 'Dense (e5â€‘largeâ€‘v2-patent)'\n",
    "best_mean_rank_bm25_config_name = 'T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)'\n",
    "\n",
    "configs = [\n",
    "    # {'name': 'Title BM25', 'method': 'bm25', 'text_type': 'title', 'preprocess': False, 'vectorizer_params': {'stop_words': 'english', 'max_features': 10000}, 'bm25_params': {'k1': 1.5, 'b': 0.75}},\n",
    "    # {'name': 'Claim1 BM25', 'method': 'bm25', 'text_type': 'claim1', 'preprocess': False, 'vectorizer_params': {'stop_words': 'english', 'max_features': 10000}, 'bm25_params': {'k1': 1.5, 'b': 0.75}},\n",
    "    {'name': best_bm25_config_name_for_rrf,\n",
    "     'method': 'bm25', 'text_type': 'title_abstract_claims',\n",
    "     'preprocess': True, 'use_stemming': False, 'use_custom_stopwords': True,\n",
    "     'vectorizer_params': {'max_features': 20000, 'ngram_range': (1, 1), 'min_df': 1},\n",
    "     'bm25_params': {'k1': 2.0, 'b': 0.9}},\n",
    "    {'name': best_mean_rank_bm25_config_name,\n",
    "     'method': 'bm25', 'text_type': 'title_abstract_claims',\n",
    "     'preprocess': True, 'use_stemming': False, 'use_custom_stopwords': True,\n",
    "     'vectorizer_params': {'max_features': 20000, 'ngram_range': (1, 1), 'min_df': 1},\n",
    "     'bm25_params': {'k1': 2.5, 'b': 0.8}},\n",
    "    # {'name': best_dense_config_name_for_rrf,\n",
    "    #  'method': 'dense', 'text_type': 'title_abstract_claims', 'preprocess': False,\n",
    "    #  'embedding_model': 'multi-qa-mpnet-base-dot-v1', 'embedding_batch_size': 128 },\n",
    "    # {'name': 'Dense (PatentSBERTa, T+A+Claims)',\n",
    "    #  'method': 'dense', 'text_type': 'title_abstract_claims', 'preprocess': False,\n",
    "    #  'embedding_model': 'AI-Growth-Lab/PatentSBERTa', 'embedding_batch_size': 64 },\n",
    "    # {\n",
    "    #     'name': 'T+A+Claims BM25 1â€‘3gram',\n",
    "    #     'method': 'bm25',\n",
    "    #     'text_type': 'title_abstract_claims',\n",
    "    #     'preprocess': True,\n",
    "    #     'vectorizer_params': {'max_features': 40000,\n",
    "    #                         'ngram_range': (1, 3),\n",
    "    #                         'token_pattern': r'(?u)\\\\b\\\\w[\\\\w\\\\-\\\\.\\\\&]+\\\\b'},\n",
    "    #     'bm25_params':   {'k1': 1.4, 'b': 0.55}\n",
    "    # },\n",
    "    {\n",
    "        'name': 'Dense (e5â€‘largeâ€‘v2-patent)',\n",
    "        'method': 'dense',\n",
    "        'text_type': 'title_abstract_claims',\n",
    "        'preprocess': False,\n",
    "        'embedding_model': 'petkopetkov/e5-large-v2-patent',\n",
    "        'embedding_batch_size': 256\n",
    "    },\n",
    "]\n",
    "\n",
    "if not SENTENCE_TRANSFORMERS_AVAILABLE:\n",
    "    print(\"\\nSentence Transformers not available, removing Dense configurations.\")\n",
    "    configs = [c for c in configs if c['method'] != 'dense']\n",
    "\n",
    "results = {}\n",
    "best_recall_100 = -1.0\n",
    "best_map_100 = -1.0\n",
    "best_config_name_recall = None\n",
    "best_config_name_map = None\n",
    "best_model_details = {}\n",
    "best_model_config = None\n",
    "\n",
    "best_bm25_ranks_train = None\n",
    "best_dense_ranks_train = None\n",
    "best_mean_rank_bm25_ranks_train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Running Configured Experiments**\n",
    "- Iterates over each configuration in `configs` and runs the corresponding experiment using `run_experiment`.\n",
    "- Uses `k_eval = 100` for metric evaluation (e.g., Recall@100, MAP@100).\n",
    "\n",
    "#### **Results Tracking**\n",
    "- Stores metrics for each experiment under `results[config_name]`.\n",
    "- Continuously updates and tracks:\n",
    "  - **Best MAP@100**:\n",
    "    - Stores name, config, and model details for the best-performing model by MAP.\n",
    "  - **Best Recall@100**:\n",
    "    - Similarly tracks the configuration with the highest recall at rank 100.\n",
    "- If the same config achieves both best MAP and best Recall, it's saved as the best overall model.\n",
    "\n",
    "#### **Error Handling**\n",
    "- Prints a message if an experiment fails or returns no metrics, ensuring traceability during batch runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiments on Training Data ===\n",
      "\n",
      "--- Running Experiment: T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9) ---\n",
      "Creating corpora...\n",
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of similarity/scores matrix: (6831, 16837)\n",
      "Generating top 16837 ranks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing BM25 (Best MAP/Recall) ranks for RRF from T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)...\n",
      "Calculating metrics...\n",
      "Recall@10: 0.5614\n",
      "Recall@100: 0.8166\n",
      "MAP@100: 0.3703\n",
      "Mean Rank: 29.6142\n",
      "Experiment 'T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)' completed in 102.90 seconds.\n",
      "*** New best MAP@100 model found: T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9) (0.3703) ***\n",
      "*** New best Recall@100 model found: T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9) (0.8166) ***\n",
      "\n",
      "--- Running Experiment: T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8) ---\n",
      "Creating corpora...\n",
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of similarity/scores matrix: (6831, 16837)\n",
      "Generating top 16837 ranks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing BM25 (Best Mean Rank) ranks for RRF from T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)...\n",
      "Calculating metrics...\n",
      "Recall@10: 0.5636\n",
      "Recall@100: 0.8200\n",
      "MAP@100: 0.3725\n",
      "Mean Rank: 29.2354\n",
      "Experiment 'T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)' completed in 101.84 seconds.\n",
      "*** New best MAP@100 model found: T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8) (0.3725) ***\n",
      "*** New best Recall@100 model found: T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8) (0.8200) ***\n",
      "\n",
      "--- Running Experiment: Dense (e5â€‘largeâ€‘v2-patent) ---\n",
      "Creating corpora...\n",
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying E5 prefixes for model: petkopetkov/e5-large-v2-patent\n",
      "Generating Dense Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [03:19<00:00,  7.40s/it]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [08:12<00:00,  7.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Dense Cosine Similarities...\n",
      "Shape of similarity/scores matrix: (6831, 16837)\n",
      "Generating top 16837 ranks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Recall@10: 0.7303\n",
      "Recall@100: 0.9641\n",
      "MAP@100: 0.4796\n",
      "Mean Rank: 12.9952\n",
      "Experiment 'Dense (e5â€‘largeâ€‘v2-patent)' completed in 727.45 seconds.\n",
      "*** New best MAP@100 model found: Dense (e5â€‘largeâ€‘v2-patent) (0.4796) ***\n",
      "*** New best Recall@100 model found: Dense (e5â€‘largeâ€‘v2-patent) (0.9641) ***\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Running Experiments on Training Data ===\")\n",
    "k_eval_metrics = 100\n",
    "\n",
    "if not all([json_citing_train, json_nonciting, mapping_dict]):\n",
    "     print(\"Cannot run experiments, datasets not loaded properly.\")\n",
    "else:\n",
    "    for config in configs:\n",
    "        metrics, model_details_run = run_experiment(config, json_citing_train, json_nonciting, mapping_dict, k_eval=k_eval_metrics)\n",
    "        if metrics:\n",
    "            results[config['name']] = metrics\n",
    "            current_recall_100 = metrics['recall@100']\n",
    "            current_map_100 = metrics['map@100']\n",
    "\n",
    "            if current_map_100 > best_map_100:\n",
    "                 best_map_100 = current_map_100\n",
    "                 best_config_name_map = config['name']\n",
    "                 best_model_details = model_details_run\n",
    "                 best_model_config = config\n",
    "                 print(f\"*** New best MAP@100 model found: {best_config_name_map} ({best_map_100:.4f}) ***\")\n",
    "\n",
    "            if current_recall_100 > best_recall_100:\n",
    "                 best_recall_100 = current_recall_100\n",
    "                 best_config_name_recall = config['name']\n",
    "                 if config['name'] == best_config_name_map:\n",
    "                     best_model_details = model_details_run\n",
    "                     best_model_config = config\n",
    "                 print(f\"*** New best Recall@100 model found: {best_config_name_recall} ({best_recall_100:.4f}) ***\")\n",
    "        else:\n",
    "            print(f\"--- Experiment {config['name']} failed or produced no results. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate RRF on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Overview**\n",
    "This section evaluates hybrid retrieval methods using **Reciprocal Rank Fusion (RRF)** to combine results from multiple base models (e.g., BM25 and Dense).\n",
    "\n",
    "#### **Prerequisites**\n",
    "- RRF is only executed if ranking results are available from:\n",
    "  - Best MAP@100 BM25 config (`best_bm25_ranks_train`)\n",
    "  - Best Mean Rank BM25 config (`best_mean_rank_bm25_ranks_train`)\n",
    "  - Best Dense config (`best_dense_ranks_train`)\n",
    "\n",
    "Warnings are shown if required rankings are missing.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Variant 1: RRF (Best MAP BM25 + Best Dense)**\n",
    "- Combines rankings from:\n",
    "  - BM25 model with best MAP@100\n",
    "  - Dense model with best MAP@100\n",
    "- Evaluates RRF with varying `k` values: `10`, `60`, and `120`.\n",
    "- For each fusion, calculates metrics:\n",
    "  - `Recall@10/20/50/100`\n",
    "  - `MAP@100`\n",
    "  - `Mean Rank`\n",
    "- Tracks and updates the best RRF configuration based on MAP@100.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Variant 2: RRF (Best Mean Rank BM25 + Best Dense)**\n",
    "- Uses a fixed `k=60` to combine:\n",
    "  - BM25 model with best Mean Rank\n",
    "  - Dense model with best MAP@100\n",
    "- Evaluates and tracks the resulting metrics similar to Variant 1.\n",
    "- Updates the best RRF config if it outperforms others based on MAP@100.\n",
    "\n",
    "---\n",
    "\n",
    "#### **RRF Results Storage**\n",
    "- All evaluated RRF configurations and their metrics are stored in `rrf_results`.\n",
    "- The best-performing fusion (by MAP@100) is saved in `best_rrf_config_details`.\n",
    "\n",
    "RRF offers a powerful ensemble approach to blend complementary retrieval strengths from lexical (BM25) and semantic (dense) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Hybrid RRF Variants on Training Data ===\n",
      "Warning: Ranks missing for BM25 MAP ('T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)') or Dense ('Dense (e5â€‘largeâ€‘v2-patent)Dense (e5â€‘largeâ€‘v2-patent)'). Cannot run primary RRF.\n",
      "Warning: Ranks missing for BM25 Mean Rank ('T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)') or Dense ('Dense (e5â€‘largeâ€‘v2-patent)Dense (e5â€‘largeâ€‘v2-patent)'). Cannot run alternative RRF.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Evaluating Hybrid RRF Variants on Training Data ===\")\n",
    "rrf_results = {}\n",
    "best_rrf_map = -1.0\n",
    "best_rrf_config_details = {}\n",
    "\n",
    "rrf_possible_best_map = best_bm25_ranks_train is not None and best_dense_ranks_train is not None\n",
    "rrf_possible_best_mean_rank = best_mean_rank_bm25_ranks_train is not None and best_dense_ranks_train is not None\n",
    "\n",
    "if not rrf_possible_best_map: print(f\"Warning: Ranks missing for BM25 MAP ('{best_bm25_config_name_for_rrf}') or Dense ('{best_dense_config_name_for_rrf}'). Cannot run primary RRF.\")\n",
    "if not rrf_possible_best_mean_rank: print(f\"Warning: Ranks missing for BM25 Mean Rank ('{best_mean_rank_bm25_config_name}') or Dense ('{best_dense_config_name_for_rrf}'). Cannot run alternative RRF.\")\n",
    "\n",
    "# Variant 1: Best MAP/Recall BM25 + Best Dense, tune RRF k\n",
    "if rrf_possible_best_map:\n",
    "    base_rank_list = [best_bm25_ranks_train, best_dense_ranks_train]\n",
    "    bm25_map_val = results.get(best_bm25_config_name_for_rrf, {}).get('map@100', 0)\n",
    "    dense_map_val = results.get(best_dense_config_name_for_rrf, {}).get('map@100', 0)\n",
    "    base_component_names = f\"BM25(MAP={bm25_map_val:.3f}) + Dense(MAP={dense_map_val:.3f})\"\n",
    "\n",
    "    for rrf_k_val in [10, 60, 120]:\n",
    "        rrf_name = f\"RRF (k={rrf_k_val}, {base_component_names})\"\n",
    "        print(f\"\\nEvaluating: {rrf_name}\")\n",
    "        try:\n",
    "            rrf_combined_ranks = combine_rankings_rrf(base_rank_list, k_rrf=rrf_k_val)\n",
    "            true_labels_rrf, predicted_labels_rrf, not_in_mapping_rrf = get_true_and_predicted(mapping_dict, rrf_combined_ranks)\n",
    "            if not predicted_labels_rrf: raise ValueError(\"No predictions from RRF combine.\")\n",
    "\n",
    "            metrics = {\n",
    "                'recall@10': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=10),\n",
    "                'recall@20': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=20),\n",
    "                'recall@50': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=50),\n",
    "                'recall@100': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=100),\n",
    "                'map@100': mean_average_precision(true_labels_rrf, predicted_labels_rrf, k=100),\n",
    "                'mean_rank': mean_ranking(true_labels_rrf, predicted_labels_rrf),\n",
    "                'num_measured': len(predicted_labels_rrf), 'not_in_mapping': not_in_mapping_rrf\n",
    "            }\n",
    "            rrf_results[rrf_name] = metrics\n",
    "            print(f\"  RRF Metrics: R@100={metrics['recall@100']:.4f}, MAP@100={metrics['map@100']:.4f}, MeanRank={metrics['mean_rank']:.2f}\")\n",
    "\n",
    "            if metrics['map@100'] > best_rrf_map:\n",
    "                best_rrf_map = metrics['map@100']\n",
    "                best_rrf_config_details = {\n",
    "                    'name': rrf_name, 'k': rrf_k_val,\n",
    "                    'bm25_config_name': best_bm25_config_name_for_rrf,\n",
    "                    'dense_config_name': best_dense_config_name_for_rrf,\n",
    "                    'metrics': metrics}\n",
    "                print(f\"  *** New best RRF configuration found: {rrf_name} (MAP@100: {best_rrf_map:.4f}) ***\")\n",
    "        except Exception as e: print(f\"Error evaluating {rrf_name}: {e}\")\n",
    "\n",
    "# Variant 2: Best Mean Rank BM25 + Best Dense, k=60\n",
    "if rrf_possible_best_mean_rank:\n",
    "    alt_rank_list = [best_mean_rank_bm25_ranks_train, best_dense_ranks_train]\n",
    "    bm25_mr_val = results.get(best_mean_rank_bm25_config_name,{}).get('mean_rank', float('inf'))\n",
    "    dense_map_val = results.get(best_dense_config_name_for_rrf,{}).get('map@100',0)\n",
    "    alt_component_names = f\"BM25(MR={bm25_mr_val:.2f}) + Dense(MAP={dense_map_val:.3f})\"\n",
    "    rrf_k_val = 60\n",
    "    rrf_name = f\"RRF (k={rrf_k_val}, {alt_component_names})\"\n",
    "    print(f\"\\nEvaluating: {rrf_name}\")\n",
    "    try:\n",
    "        rrf_combined_ranks = combine_rankings_rrf(alt_rank_list, k_rrf=rrf_k_val)\n",
    "        true_labels_rrf, predicted_labels_rrf, not_in_mapping_rrf = get_true_and_predicted(mapping_dict, rrf_combined_ranks)\n",
    "        if not predicted_labels_rrf: raise ValueError(\"No predictions from RRF combine.\")\n",
    "\n",
    "        metrics = {\n",
    "            'recall@10': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=10),\n",
    "            'recall@20': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=20),\n",
    "            'recall@50': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=50),\n",
    "            'recall@100': mean_recall_at_k(true_labels_rrf, predicted_labels_rrf, k=100),\n",
    "            'map@100': mean_average_precision(true_labels_rrf, predicted_labels_rrf, k=100),\n",
    "            'mean_rank': mean_ranking(true_labels_rrf, predicted_labels_rrf),\n",
    "            'num_measured': len(predicted_labels_rrf), 'not_in_mapping': not_in_mapping_rrf\n",
    "        }\n",
    "        rrf_results[rrf_name] = metrics\n",
    "        print(f\"  RRF Metrics: R@100={metrics['recall@100']:.4f}, MAP@100={metrics['map@100']:.4f}, MeanRank={metrics['mean_rank']:.2f}\")\n",
    "\n",
    "        if metrics['map@100'] > best_rrf_map:\n",
    "            best_rrf_map = metrics['map@100']\n",
    "            best_rrf_config_details = {\n",
    "                'name': rrf_name, 'k': rrf_k_val,\n",
    "                'bm25_config_name': best_mean_rank_bm25_config_name, # Use the mean rank one\n",
    "                'dense_config_name': best_dense_config_name_for_rrf,\n",
    "                'metrics': metrics}\n",
    "            print(f\"  *** New best RRF configuration found: {rrf_name} (MAP@100: {best_rrf_map:.4f}) ***\")\n",
    "    except Exception as e: print(f\"Error evaluating {rrf_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine final best prediction method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "Identify the best-performing prediction approach using **MAP@100** as the primary evaluation metric.\n",
    "\n",
    "#### **Selection Logic**\n",
    "- Compares the best RRF configuration's `MAP@100` (`best_rrf_map`) with the best single model's `MAP@100` (`best_map_100`).\n",
    "- **If RRF outperforms all single models**:\n",
    "  - Selects RRF as the best method.\n",
    "  - Stores its config and metrics in `final_prediction_config`.\n",
    "- **Otherwise**:\n",
    "  - Selects the best single model configuration.\n",
    "  - Also stores associated model details (e.g., vectorizer or embeddings).\n",
    "\n",
    "#### **Fallback Handling**\n",
    "- If no valid method is determined, logs a warning for further inspection.\n",
    "\n",
    "#### **Results Update**\n",
    "- Merges `rrf_results` into the overall `results` dictionary for unified tracking.\n",
    "\n",
    "This step finalizes which method should be used for making predictions and optionally for downstream testing or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Determining Best Prediction Method ---\n",
      "Best method is Single Model: 'Dense (e5â€‘largeâ€‘v2-patent)' (MAP@100: 0.4796)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Determining Best Prediction Method ---\")\n",
    "best_method_for_prediction = None\n",
    "final_prediction_config = None\n",
    "\n",
    "if best_rrf_map > best_map_100 and best_rrf_config_details:\n",
    "    print(f\"Best method is RRF: '{best_rrf_config_details['name']}' (MAP@100: {best_rrf_map:.4f})\")\n",
    "    best_method_for_prediction = 'rrf'\n",
    "    final_prediction_config = best_rrf_config_details # Store RRF details\n",
    "elif best_config_name_map:\n",
    "    print(f\"Best method is Single Model: '{best_config_name_map}' (MAP@100: {best_map_100:.4f})\")\n",
    "    best_method_for_prediction = best_config_name_map\n",
    "    final_prediction_config = best_model_config # Config dict of the best single model\n",
    "    if final_prediction_config: final_prediction_config['details'] = best_model_details # Attach fitted objects\n",
    "else:\n",
    "    print(\"Warning: Could not determine best method. Check experiment results and logs.\")\n",
    "\n",
    "results.update(rrf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Results Summary ===\n",
      "                                               recall@10  recall@20  \\\n",
      "Dense (e5â€‘largeâ€‘v2-patent)                      0.730288   0.828544   \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)   0.563578   0.649344   \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)   0.561397   0.646806   \n",
      "\n",
      "                                               recall@50  recall@100  \\\n",
      "Dense (e5â€‘largeâ€‘v2-patent)                      0.925892    0.964115   \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)   0.753709    0.820031   \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)   0.751244    0.816554   \n",
      "\n",
      "                                                map@100  mean_rank  \\\n",
      "Dense (e5â€‘largeâ€‘v2-patent)                     0.479582  12.995176   \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)  0.372483  29.235368   \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)  0.370302  29.614246   \n",
      "\n",
      "                                               num_measured  not_in_mapping  \n",
      "Dense (e5â€‘largeâ€‘v2-patent)                           6831.0             0.0  \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.5, b=0.8)        6831.0             0.0  \n",
      "T+A+Claims BM25 (Pre, ngram=1, k1=2.0, b=0.9)        6831.0             0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n=== Experiment Results Summary ===\")\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results).T.sort_values(by='map@100', ascending=False) # Sort by MAP\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(results_df)\n",
    "    pd.reset_option('display.max_rows')\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    k_values_plot = [10, 20, 50, 100]\n",
    "    sorted_results_plot = sorted(results.items(), key=lambda item: item[1].get('recall@100', 0), reverse=True)\n",
    "    for name, metrics_res in sorted_results_plot:\n",
    "        recalls = [metrics_res.get(f'recall@{k}', 0) for k in k_values_plot]\n",
    "        if any(not isinstance(r, (int, float)) for r in recalls): continue\n",
    "        plt.plot(k_values_plot, recalls, label=f\"{name} (MAP@100: {metrics_res.get('map@100', 0):.3f})\", marker='o', linewidth=1.5, markersize=5)\n",
    "\n",
    "    plt.xlabel('Top K')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Recall@K Comparison of Methods (Train Set)')\n",
    "    plt.xticks(k_values_plot)\n",
    "    plt.legend(loc='best', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test predictions for CodaBench\n",
    "\n",
    "#### **Generating Predictions Using Best Method**\n",
    "- Determines how to generate predictions based on the selected best-performing method (`best_method_for_prediction`), which could be:\n",
    "  - **RRF-based (Hybrid)**: Combines BM25 and Dense model rankings.\n",
    "  - **Single Model**: Uses either BM25, TF-IDF, or Dense embedding-based similarity.\n",
    "\n",
    "---\n",
    "\n",
    "#### **RRF Workflow**\n",
    "- Validates availability of component configs and required libraries.\n",
    "- Steps:\n",
    "  1. **Corpus Preparation**:\n",
    "     - Creates separate citing and non-citing corpora for both BM25 and Dense models.\n",
    "  2. **BM25 Scoring**:\n",
    "     - Fits a `CountVectorizer` on training + non-citing data.\n",
    "     - Scores test citing documents using a fresh `BM25Score` model.\n",
    "  3. **Dense Embedding & Similarity**:\n",
    "     - Generates Sentence Transformer embeddings for test corpora.\n",
    "     - Computes cosine similarity matrix.\n",
    "  4. **Rank Fusion via RRF**:\n",
    "     - Combines top-ranked results using Reciprocal Rank Fusion (RRF) with the best `k`.\n",
    "     - Filters to top `k_submission` (e.g., 100) for final output.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Single Model Workflow**\n",
    "- Loads previously stored components from training:\n",
    "  - Vectorizer / BM25 model / Dense embeddings.\n",
    "- Based on method:\n",
    "  - **TF-IDF**: Transforms test citing docs and applies `linear_kernel` similarity.\n",
    "  - **BM25**: Transforms test citing docs and uses stored BM25 model to score.\n",
    "  - **Dense**: Encodes citing texts and compares to stored non-citing embeddings using cosine similarity.\n",
    "- Produces top-k predictions from the similarity scores.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Output Handling**\n",
    "- Saves final predictions to a JSON file (default: `prediction1.json`) with structure:\n",
    "  ```json\n",
    "  {\n",
    "      \"citing_id_1\": [\"ranked_id_1\", \"ranked_id_2\", ..., \"ranked_id_100\"],\n",
    "      ...\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating Test Predictions for CodaBench ===\n",
      "Selected approach for final prediction: Dense (e5â€‘largeâ€‘v2-patent)\n",
      "\n",
      "Generating predictions using best single model: Dense (e5â€‘largeâ€‘v2-patent)\n",
      "Creating test citing corpus...\n",
      "Creating corpus for text_type: 'title_abstract_claims'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying method: dense\n",
      "Applying E5 query prefix for test prediction with model: petkopetkov/e5-large-v2-patent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Dense Cosine Similarities...\n",
      "Shape of test similarity/scores matrix: (1000, 16837)\n",
      "Generating top 100 ranks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated single model predictions for 1000 test patents.\n",
      "\n",
      "Saving final predictions (1000 queries) to prediction1.json using method: Dense (e5â€‘largeâ€‘v2-patent)...\n",
      "Predictions saved successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Generating Test Predictions for CodaBench ===\")\n",
    "\n",
    "if not best_method_for_prediction:\n",
    "     print(\"Error: No best method determined. Cannot generate predictions.\")\n",
    "     exit()\n",
    "\n",
    "print(f\"Selected approach for final prediction: {best_method_for_prediction}\")\n",
    "\n",
    "k_submission = 100\n",
    "test_predictions = None\n",
    "output_filename = 'prediction1.json'\n",
    "\n",
    "if best_method_for_prediction == 'rrf':\n",
    "    print(\"\\nGenerating RRF predictions for test set...\")\n",
    "    if not final_prediction_config or 'bm25_config_name' not in final_prediction_config or 'dense_config_name' not in final_prediction_config:\n",
    "         print(\"Error: RRF selected, but configuration details are missing.\")\n",
    "    else:\n",
    "        config_bm25 = next((c for c in configs if c['name'] == final_prediction_config['bm25_config_name']), None)\n",
    "        config_dense = next((c for c in configs if c['name'] == final_prediction_config['dense_config_name']), None)\n",
    "        rrf_k_val = final_prediction_config['k']\n",
    "\n",
    "        if not config_bm25 or not config_dense:\n",
    "            print(\"Error: Could not find original configurations for RRF components. Cannot proceed.\")\n",
    "        elif not SENTENCE_TRANSFORMERS_AVAILABLE and config_dense['method'] == 'dense':\n",
    "             print(\"Error: RRF requires dense model, but sentence-transformers is not available.\")\n",
    "        else:\n",
    "            try:\n",
    "                # A. Prepare Corpora\n",
    "                print(\"Creating corpora for RRF test prediction...\")\n",
    "                citing_corpus_test_bm25 = create_corpus(json_citing_test, config_bm25['text_type'], preprocess=True, config=config_bm25)\n",
    "                citing_texts_test_bm25 = [doc['text'] for doc in citing_corpus_test_bm25]\n",
    "                nonciting_corpus_bm25 = create_corpus(json_nonciting, config_bm25['text_type'], preprocess=True, config=config_bm25)\n",
    "                nonciting_texts_bm25 = [doc['text'] for doc in nonciting_corpus_bm25]\n",
    "\n",
    "                citing_corpus_test_dense = create_corpus(json_citing_test, config_dense['text_type'], preprocess=False, config=config_dense)\n",
    "                citing_texts_test_dense = [doc['text'] for doc in citing_corpus_test_dense]\n",
    "                nonciting_corpus_dense = create_corpus(json_nonciting, config_dense['text_type'], preprocess=False, config=config_dense)\n",
    "                nonciting_texts_dense = [doc['text'] for doc in nonciting_corpus_dense]\n",
    "\n",
    "                if not all([citing_corpus_test_bm25, nonciting_corpus_bm25, citing_corpus_test_dense, nonciting_corpus_dense]):\n",
    "                    raise ValueError(\"One or more corpora creation failed for RRF.\")\n",
    "\n",
    "                # B. Get BM25 Ranks for Test Set\n",
    "                print(f\"\\nCalculating BM25 scores for test set (using {config_bm25['name']} settings)...\")\n",
    "                train_corpus_bm25 = create_corpus(json_citing_train, config_bm25['text_type'], preprocess=True, config=config_bm25)\n",
    "                all_train_texts_bm25 = [d['text'] for d in train_corpus_bm25] + nonciting_texts_bm25\n",
    "                bm25_vectorizer = CountVectorizer(**config_bm25['vectorizer_params'])\n",
    "                bm25_vectorizer.fit(tqdm(all_train_texts_bm25, desc=\"Fit BM25 Vectorizer\", leave=False))\n",
    "                test_citing_counts = bm25_vectorizer.transform(tqdm(citing_texts_test_bm25, desc=\"Transform Test Citing (BM25)\"))\n",
    "                test_nonciting_counts = bm25_vectorizer.transform(tqdm(nonciting_texts_bm25, desc=\"Transform Non-Citing (BM25)\"))\n",
    "                bm25_model_test = BM25Score(test_nonciting_counts, **config_bm25['bm25_params'])\n",
    "                bm25_model_test.fit()\n",
    "                test_bm25_scores = bm25_model_test.predict(test_citing_counts)\n",
    "                print(f\"Shape of test BM25 scores matrix: {test_bm25_scores.shape}\")\n",
    "                test_bm25_ranks = top_k_ranks(citing_corpus_test_bm25, nonciting_corpus_bm25, test_bm25_scores, k=max(k_submission * 2, 500)) # Increase candidate pool size\n",
    "\n",
    "                dense_model_name = config_dense['embedding_model']\n",
    "                needs_prefix = dense_model_name and (\"e5\" in dense_model_name.lower())\n",
    "\n",
    "                if needs_prefix:\n",
    "                    print(f\"Applying E5 prefixes for RRF dense component: {dense_model_name}\")\n",
    "                    prefixed_citing_texts_test_dense = [add_query_prefix(text) for text in citing_texts_test_dense]\n",
    "                    prefixed_nonciting_texts_dense = [add_passage_prefix(text) for text in nonciting_texts_dense]\n",
    "                else:\n",
    "                    prefixed_citing_texts_test_dense = citing_texts_test_dense\n",
    "                    prefixed_nonciting_texts_dense = nonciting_texts_dense\n",
    "\n",
    "                # C. Get Dense Ranks for Test Set\n",
    "                print(f\"\\nCalculating Dense embeddings/similarities for test set (using {config_dense['name']} settings)...\")\n",
    "                test_citing_embed = create_dense_embeddings(prefixed_citing_texts_test_dense, model_name=config_dense['embedding_model'], batch_size=config_dense['embedding_batch_size'])\n",
    "                test_nonciting_embed = create_dense_embeddings(prefixed_nonciting_texts_dense, model_name=config_dense['embedding_model'], batch_size=config_dense['embedding_batch_size'])\n",
    "                if test_citing_embed is None or test_nonciting_embed is None: raise ValueError(\"Dense embedding failed for test.\")\n",
    "                test_dense_sim = calculate_dense_similarity(test_citing_embed, test_nonciting_embed)\n",
    "                if test_dense_sim is None: raise ValueError(\"Dense similarity failed for test.\")\n",
    "                print(f\"Shape of test Dense similarity matrix: {test_dense_sim.shape}\")\n",
    "                test_dense_ranks = top_k_ranks(citing_corpus_test_dense, nonciting_corpus_dense, test_dense_sim, k=max(k_submission * 2, 500)) # Increase candidate pool size\n",
    "\n",
    "                # D. Combine Ranks using RRF with the best k\n",
    "                print(f\"\\nCombining test rankings using RRF (k={rrf_k_val})...\")\n",
    "                common_test_citing_ids = set(test_bm25_ranks.keys()).intersection(test_dense_ranks.keys())\n",
    "                if len(common_test_citing_ids) < len(citing_corpus_test_bm25): # Check if we lost test queries\n",
    "                     print(f\"Warning: Mismatch in test citing IDs between BM25 ({len(test_bm25_ranks)}) and Dense ({len(test_dense_ranks)}). Using {len(common_test_citing_ids)} common IDs.\")\n",
    "                rank_list_for_rrf = [\n",
    "                    {qid: ranks for qid, ranks in test_bm25_ranks.items() if qid in common_test_citing_ids},\n",
    "                    {qid: ranks for qid, ranks in test_dense_ranks.items() if qid in common_test_citing_ids}\n",
    "                ]\n",
    "                test_predictions_rrf_combined = combine_rankings_rrf(rank_list_for_rrf, k_rrf=rrf_k_val)\n",
    "\n",
    "                # E. Trim to final k for submission\n",
    "                test_predictions = {qid: ranks[:k_submission] for qid, ranks in test_predictions_rrf_combined.items()}\n",
    "                print(f\"Generated RRF predictions for {len(test_predictions)} test patents.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during RRF test prediction generation: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                test_predictions = None # Ensure None on error\n",
    "\n",
    "elif best_method_for_prediction and final_prediction_config: # Fallback to best single model\n",
    "    print(f\"\\nGenerating predictions using best single model: {best_method_for_prediction}\")\n",
    "    best_config = final_prediction_config\n",
    "    single_model_details = best_config.get('details', {})\n",
    "\n",
    "    if not single_model_details:\n",
    "         print(f\"Error: Details (fitted models) for the best single model '{best_method_for_prediction}' are missing.\")\n",
    "    elif best_config['method'] == 'dense' and not SENTENCE_TRANSFORMERS_AVAILABLE:\n",
    "         print(\"Error: Best single model is dense, but sentence-transformers not available.\")\n",
    "    else:\n",
    "        try:\n",
    "            print(\"Creating test citing corpus...\")\n",
    "            citing_corpus_test = create_corpus(json_citing_test, best_config['text_type'], preprocess=best_config.get('preprocess', False), config=best_config)\n",
    "            citing_texts_test = [doc['text'] for doc in citing_corpus_test]\n",
    "\n",
    "            # Retrieve components from the *training run* details stored in best_config\n",
    "            fitted_vectorizer = single_model_details.get('vectorizer')\n",
    "            fitted_bm25_model = single_model_details.get('bm25_model')\n",
    "            nonciting_corpus_for_ranking = single_model_details.get('nonciting_corpus')\n",
    "            nonciting_matrix_tfidf = single_model_details.get('nonciting_matrix')\n",
    "            nonciting_embeddings = single_model_details.get('nonciting_embeddings')\n",
    "\n",
    "            if not citing_corpus_test or not nonciting_corpus_for_ranking:\n",
    "                print(\"Test citing corpus or non-citing corpus for ranking is missing/empty.\")\n",
    "            else:\n",
    "                test_similarity_scores = None\n",
    "                print(f\"Applying method: {best_config['method']}\")\n",
    "                if best_config['method'] == 'tfidf':\n",
    "                     if fitted_vectorizer and nonciting_matrix_tfidf is not None:\n",
    "                         citing_matrix_test = fitted_vectorizer.transform(tqdm(citing_texts_test, desc=\"Transform Test Citing (TFIDF)\"))\n",
    "                         test_similarity_scores = linear_kernel(citing_matrix_test, nonciting_matrix_tfidf)\n",
    "                     else: print(\"Error: Missing components for TF-IDF prediction.\")\n",
    "                elif best_config['method'] == 'bm25':\n",
    "                     if fitted_vectorizer and fitted_bm25_model:\n",
    "                         citing_matrix_test = fitted_vectorizer.transform(tqdm(citing_texts_test, desc=\"Transform Test Citing (BM25)\"))\n",
    "                         test_similarity_scores = fitted_bm25_model.predict(citing_matrix_test)\n",
    "                     else: print(\"Error: Missing components for BM25 prediction.\")\n",
    "                elif best_config['method'] == 'dense':\n",
    "                    model_name = best_config.get('embedding_model')\n",
    "                    needs_prefix = model_name and (\"e5\" in model_name.lower())\n",
    "\n",
    "                    if needs_prefix:\n",
    "                        print(f\"Applying E5 query prefix for test prediction with model: {model_name}\")\n",
    "                        prefixed_citing_texts_test = [add_query_prefix(text) for text in citing_texts_test]\n",
    "                    else:\n",
    "                        prefixed_citing_texts_test = citing_texts_test\n",
    "\n",
    "                    if nonciting_embeddings is not None:\n",
    "                        citing_embeddings_test = create_dense_embeddings(\n",
    "                             prefixed_citing_texts_test,\n",
    "                             model_name=best_config.get('embedding_model'),\n",
    "                             batch_size=best_config.get('embedding_batch_size')\n",
    "                        )\n",
    "                        if citing_embeddings_test is not None:\n",
    "                              test_similarity_scores = calculate_dense_similarity(citing_embeddings_test, nonciting_embeddings)\n",
    "                        else: print(\"Error generating test dense embeddings.\")\n",
    "                    else: print(\"Error: Missing non-citing embeddings for dense prediction.\")\n",
    "\n",
    "                if test_similarity_scores is not None:\n",
    "                    print(f\"Shape of test similarity/scores matrix: {test_similarity_scores.shape}\")\n",
    "                    test_predictions = top_k_ranks(citing_corpus_test, nonciting_corpus_for_ranking, test_similarity_scores, k=k_submission)\n",
    "                    print(f\"Generated single model predictions for {len(test_predictions)} test patents.\")\n",
    "                else:\n",
    "                    print(\"Failed to compute test similarity scores for single best model.\")\n",
    "                    test_predictions = None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during single model test prediction generation: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            test_predictions = None\n",
    "else:\n",
    "    print(\"No best model configuration identified or details missing. Cannot generate predictions.\")\n",
    "\n",
    "\n",
    "# 5. Save Final Predictions to JSON\n",
    "if test_predictions is not None and isinstance(test_predictions, dict) and test_predictions:\n",
    "    print(f\"\\nSaving final predictions ({len(test_predictions)} queries) to {output_filename} using method: {best_method_for_prediction}...\")\n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(test_predictions, f, indent=4)\n",
    "        print(\"Predictions saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving predictions: {e}\")\n",
    "elif test_predictions is None:\n",
    "     print(\"No predictions were generated due to errors.\")\n",
    "else:\n",
    "     print(\"Predictions dictionary is empty, not saving.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from sentence_transformers import SentenceTransformer, CrossEncoder, models, util\n",
    "# from tqdm import tqdm\n",
    "# from pathlib import Path\n",
    "# import time\n",
    "# import types\n",
    "# import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Base Configuration (`config`)**\n",
    "Defines default settings used across all experiments, which can be overridden per experiment:\n",
    "\n",
    "- **File Paths**:\n",
    "  - `query_list_file`: List of queries for prediction.\n",
    "  - `pre_ranking_file`: Initial candidate document rankings (e.g., from BM25).\n",
    "  - `queries_content_file`, `documents_content_file`: Content and features for queries and candidate documents.\n",
    "\n",
    "- **Model Defaults**:\n",
    "  - `reranker_type`: `'bi-encoder'` (default, can also be `'cross-encoder'`)\n",
    "  - `bi_encoder_model`: `AI-Growth-Lab/PatentSBERTa`\n",
    "  - `cross_encoder_model`: `cross-encoder/ms-marco-MiniLM-L-6-v2`\n",
    "  - `text_type`: `'tac1'` (can be changed to e.g., `'claims'` or `'TA'`)\n",
    "  - `max_length`: Token limit for encoding input text.\n",
    "\n",
    "- **Execution Settings**:\n",
    "  - `batch_size`: Batch size for model inference.\n",
    "  - `device`: Automatically set to `'cuda'` if available, else falls back to `'cpu'`.\n",
    "\n",
    "- **Output Settings**:\n",
    "  - `save_individual_predictions`: If `True`, saves output JSON for each experiment.\n",
    "  - `output_file_prefix`: Prefix for saved prediction files.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Experiment Definitions (`experiments`)**\n",
    "A list of experiment configurations to run:\n",
    "\n",
    "- **Bi-Encoder Experiments**:\n",
    "  - Vary in model (`PatentSBERTa`, `MPNet`, `MultiQA`) and text type (`tac1`, `claims`).\n",
    "- **Cross-Encoder Experiments**:\n",
    "  - Use `cross-encoder/ms-marco-MiniLM-L-6-v2`.\n",
    "  - Test different text types: `tac1`, `claims`, and `TA`.\n",
    "\n",
    "Each experiment includes:\n",
    "- `exp_id`: A unique identifier.\n",
    "- `reranker_type`: Model type (`bi-encoder` or `cross-encoder`).\n",
    "- Model-specific settings: Either `bi_encoder_model` or `cross_encoder_model`.\n",
    "- `text_type`: Indicates which section(s) of the patent text to use.\n",
    "\n",
    "---\n",
    "\n",
    "This setup provides a flexible, modular framework for running multiple reranking experiments efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     # --- Data Files ---\n",
    "#     'base_dir': '.',\n",
    "#     'query_list_file': 'test_queries.json',\n",
    "#     'pre_ranking_file': 'shuffled_pre_ranking.json',\n",
    "#     'queries_content_file': 'queries_content_with_features.json',\n",
    "#     'documents_content_file': 'documents_content_with_features.json',\n",
    "#     'reranker_type': 'bi-encoder',\n",
    "#     'bi_encoder_model': 'AI-Growth-Lab/PatentSBERTa',\n",
    "#     'cross_encoder_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "#     'text_type': 'tac1',\n",
    "#     'max_length': 512,\n",
    "#     'batch_size': 32,\n",
    "#     'device': None,\n",
    "#     'save_individual_predictions': True,\n",
    "#     'output_file_prefix': 'prediction_exp',\n",
    "# }\n",
    "\n",
    "# experiments = [\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_PatentSBERTa_tac1',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'AI-Growth-Lab/PatentSBERTa',\n",
    "#         'text_type': 'tac1',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_E5_patent_tac1',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'petkopetkov/e5-large-v2-patent',\n",
    "#         'text_type': 'tac1',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_E5_patent_claims',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'petkopetkov/e5-large-v2-patent',\n",
    "#         'text_type': 'claims',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_E5_patent_tac1',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'petkopetkov/e5-large-v2-patent',\n",
    "#         'text_type': 'tac1',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_MPNet_tac1',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'all-mpnet-base-v2',\n",
    "#         'text_type': 'tac1',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_PatentSBERTa_claims',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'AI-Growth-Lab/PatentSBERTa',\n",
    "#         'text_type': 'claims',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_MPNet_claims',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'all-mpnet-base-v2',\n",
    "#         'text_type': 'claims',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'BiEnc_MultiQA_tac1',\n",
    "#         'reranker_type': 'bi-encoder',\n",
    "#         'bi_encoder_model': 'multi-qa-mpnet-base-dot-v1',\n",
    "#         'text_type': 'tac1',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'CrossEnc_L6_tac1',\n",
    "#         'reranker_type': 'cross-encoder',\n",
    "#         'cross_encoder_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "#         'text_type': 'tac1',\n",
    "#     },\n",
    "#     {\n",
    "#         'exp_id': 'CrossEnc_L6_claims',\n",
    "#         'reranker_type': 'cross-encoder',\n",
    "#         'cross_encoder_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "#         'text_type': 'claims',\n",
    "#      },\n",
    "#      {\n",
    "#         'exp_id': 'CrossEnc_L6_TA',\n",
    "#         'reranker_type': 'cross-encoder',\n",
    "#         'cross_encoder_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "#         'text_type': 'TA',\n",
    "#      },\n",
    "# ]\n",
    "\n",
    "# if config['device'] is None:\n",
    "#     config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# elif config['device'] == 'cuda' and not torch.cuda.is_available():\n",
    "#     print(\"Warning: CUDA requested but not available. Using CPU.\")\n",
    "#     config['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "We define helper functions so we can easily work with the json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_json_file(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "#         return data\n",
    "#     except FileNotFoundError: print(f\"Error: File not found at {file_path}\"); return None\n",
    "#     except json.JSONDecodeError: print(f\"Error: Could not decode JSON from {file_path}\"); return None\n",
    "#     except Exception as e: print(f\"An unexpected error occurred loading {file_path}: {e}\"); return None\n",
    "\n",
    "# def save_json_file(data, file_path):\n",
    "#     print(f\"Saving predictions to: {file_path}\")\n",
    "#     try:\n",
    "#         output_dir = os.path.dirname(file_path)\n",
    "#         if output_dir: os.makedirs(output_dir, exist_ok=True)\n",
    "#         with open(file_path, 'w', encoding='utf-8') as f: json.dump(data, f, indent=2)\n",
    "#     except Exception as e: print(f\"An error occurred saving to {file_path}: {e}\")\n",
    "\n",
    "# def load_content_data(file_path):\n",
    "#     data = load_json_file(file_path)\n",
    "#     if data is None: return {}\n",
    "#     print(f\"Processing content file: {os.path.basename(file_path)}\")\n",
    "#     content_dict = {}\n",
    "#     key_options = ['FAN', 'Application_Number']\n",
    "#     for item in tqdm(data, desc=\"Loading content\", leave=False):\n",
    "#         fan_key = None\n",
    "#         temp_key_val = None\n",
    "#         for key_name in key_options:\n",
    "#             if key_name in item:\n",
    "#                 temp_key_val = item[key_name]\n",
    "#                 if key_name == 'Application_Number' and 'Application_Category' in item:\n",
    "#                    fan_key = str(temp_key_val) + str(item.get('Application_Category', ''))\n",
    "#                 else:\n",
    "#                    fan_key = str(temp_key_val)\n",
    "#                 break\n",
    "#         if fan_key and 'Content' in item:\n",
    "#              content_dict[fan_key] = item['Content']\n",
    "#     return content_dict\n",
    "\n",
    "# def extract_text(content_dict, text_type=\"TA\"):\n",
    "#     if not isinstance(content_dict, dict): return \"\"\n",
    "#     text_parts = []\n",
    "#     if text_type in [\"TA\", \"tac1\", \"full\", \"title_abstract\"]:\n",
    "#         text_parts.append(content_dict.get(\"title\", \"\"))\n",
    "#         text_parts.append(content_dict.get(\"pa01\", \"\"))\n",
    "#     if text_type in [\"claims\", \"tac1\", \"full\"]:\n",
    "#         claims, first_claim = [], None\n",
    "#         claim_keys = [key for key in content_dict if key.startswith('c-')]\n",
    "#         def get_sort_key(key_string):\n",
    "#             parts = key_string.split('-', 1); return int(parts[1]) if len(parts) == 2 and parts[1].isdigit() else float('inf')\n",
    "#         sorted_keys = sorted(claim_keys, key=get_sort_key)\n",
    "#         for key in sorted_keys:\n",
    "#             claim_text = content_dict.get(key, \"\")\n",
    "#             if claim_text:\n",
    "#                 claims.append(claim_text)\n",
    "#                 if first_claim is None and text_type == \"tac1\": first_claim = claim_text\n",
    "#         if text_type == \"claims\" or text_type == \"full\": text_parts.extend(claims)\n",
    "#         elif text_type == \"tac1\" and first_claim: text_parts.append(first_claim)\n",
    "#     if text_type in [\"description\", \"full\"]:\n",
    "#         desc_parts = []\n",
    "#         desc_keys = [key for key in content_dict if key.startswith('p')]\n",
    "#         def get_p_sort_key(key_string):\n",
    "#              parts = key_string.split('-', 1); return int(parts[1]) if len(parts) == 2 and parts[1].isdigit() else float('inf')\n",
    "#         sorted_keys = sorted(desc_keys, key=get_p_sort_key)\n",
    "#         for key in sorted_keys: desc_parts.append(content_dict.get(key,\"\"))\n",
    "#         text_parts.extend(desc_parts)\n",
    "#     if text_type == \"features\": text_parts.append(content_dict.get(\"features\", \"\"))\n",
    "#     result = \" \".join(filter(None, text_parts)).strip()\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform re-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute reranking of candidate documents for a list of queries using either a **bi-encoder** or **cross-encoder** model from the Sentence Transformers framework.\n",
    "\n",
    "#### **Workflow Overview**\n",
    "1. **Model Loading**:\n",
    "   - Loads a SentenceTransformer (bi-encoder) or CrossEncoder model onto the specified device.\n",
    "   - Applies a max sequence length and batch size as per config.\n",
    "\n",
    "2. **Per-Query Processing**:\n",
    "   - For each query:\n",
    "     - Retrieves the query text and candidate document texts using the specified `text_type` (e.g., `'tac1'`, `'claims'`, etc.).\n",
    "     - Skips queries with missing data.\n",
    "     - Filters out documents with missing or empty content.\n",
    "\n",
    "3. **Scoring**:\n",
    "   - **Bi-Encoder**: Encodes query and documents into embeddings and computes cosine similarity.\n",
    "   - **Cross-Encoder**: Scores query-document pairs directly using the model.\n",
    "   - Handles exceptions and assigns fallback scores to maintain consistent ranking length.\n",
    "\n",
    "4. **Ranking**:\n",
    "   - Ranks candidates by score (descending).\n",
    "   - Ensures all originally ranked documents are included.\n",
    "   - Truncates results to original candidate list length.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Robustness Features**\n",
    "- Handles missing or malformed content gracefully.\n",
    "- Applies fallback scores to maintain list structure if model scoring fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_reranking(exp_config, query_ids, pre_ranking_data, queries_content, documents_content):\n",
    "#     device = torch.device(exp_config['device'])\n",
    "#     reranker_type = exp_config['reranker_type']\n",
    "#     text_type = exp_config['text_type']\n",
    "#     model = None\n",
    "#     model_name = \"\"\n",
    "\n",
    "#     # --- Load Model ---\n",
    "#     try:\n",
    "#         if reranker_type == 'bi-encoder':\n",
    "#             model_name = exp_config.get('bi_encoder_model')\n",
    "#             if not model_name: raise ValueError(\"bi_encoder_model must be specified\")\n",
    "#             print(f\"Loading Bi-Encoder model: {model_name}...\")\n",
    "#             model = SentenceTransformer(model_name, device=device)\n",
    "#             model.max_seq_length = exp_config['max_length']\n",
    "\n",
    "#         elif reranker_type == 'cross-encoder':\n",
    "#             model_name = exp_config.get('cross_encoder_model')\n",
    "#             if not model_name: raise ValueError(\"cross_encoder_model must be specified\")\n",
    "#             print(f\"Loading Cross-Encoder model: {model_name}...\")\n",
    "#             model = CrossEncoder(model_name, device=device, max_length=exp_config['max_length'])\n",
    "#         else:\n",
    "#              raise ValueError(f\"Invalid reranker_type: {reranker_type}\")\n",
    "#         print(f\"Model '{model_name}' loaded.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nError loading model '{model_name}' for experiment '{exp_config.get('exp_id', 'N/A')}': {e}\")\n",
    "#         return None\n",
    "\n",
    "#     # --- Re-ranking Process ---\n",
    "#     results = {}\n",
    "#     pbar = tqdm(query_ids, desc=f\"Re-ranking ({exp_config.get('exp_id', 'N/A')})\", leave=False)\n",
    "#     for query_id in pbar:\n",
    "#         candidate_doc_ids = pre_ranking_data.get(query_id, []) # query_id is string, doc_ids are strings\n",
    "#         query_content_dict = queries_content.get(query_id) # query_id is string\n",
    "\n",
    "#         if not candidate_doc_ids: results[query_id] = []; continue\n",
    "#         if not query_content_dict: results[query_id] = candidate_doc_ids; continue\n",
    "\n",
    "#         query_text = extract_text(query_content_dict, text_type)\n",
    "#         if not query_text: results[query_id] = candidate_doc_ids; continue\n",
    "\n",
    "#         valid_docs_texts = {}\n",
    "#         for doc_id in candidate_doc_ids:\n",
    "#             doc_content_dict = documents_content.get(doc_id)\n",
    "#             if doc_content_dict:\n",
    "#                 doc_text = extract_text(doc_content_dict, text_type)\n",
    "#                 if doc_text: valid_docs_texts[doc_id] = doc_text\n",
    "\n",
    "#         valid_doc_ids = list(valid_docs_texts.keys())\n",
    "#         if not valid_doc_ids: results[query_id] = candidate_doc_ids; continue\n",
    "\n",
    "#         doc_scores_calculated = {}\n",
    "#         try:\n",
    "#             doc_texts_for_scoring = [valid_docs_texts[doc_id] for doc_id in valid_doc_ids]\n",
    "\n",
    "#             if reranker_type == 'bi-encoder':\n",
    "#                 model_name_rerank = exp_config.get('bi_encoder_model')\n",
    "#                 needs_prefix_rerank = model_name_rerank and (\"e5\" in model_name_rerank.lower())\n",
    "\n",
    "#                 # Prepare texts for encoding\n",
    "#                 query_text_to_encode = add_query_prefix(query_text) if needs_prefix_rerank else query_text\n",
    "#                 docs_texts_to_encode = [add_passage_prefix(doc_text) for doc_text in doc_texts_for_scoring] if needs_prefix_rerank else doc_texts_for_scoring\n",
    "                \n",
    "#                 query_embedding = model.encode(query_text_to_encode, convert_to_tensor=True, show_progress_bar=False).to(device)\n",
    "#                 doc_embeddings = model.encode(docs_texts_to_encode, convert_to_tensor=True, show_progress_bar=False, batch_size=exp_config['batch_size']).to(device)\n",
    "#                 if query_embedding is None or doc_embeddings is None or len(doc_embeddings) == 0: raise RuntimeError(\"Embedding generation failed\")\n",
    "#                 if query_embedding.shape[0] == 0 or doc_embeddings.shape[0] == 0: raise RuntimeError(\"Embedding tensor is empty\")\n",
    "#                 cosine_scores = util.cos_sim(query_embedding, doc_embeddings)[0].cpu().numpy()\n",
    "#                 doc_scores_calculated = dict(zip(valid_doc_ids, cosine_scores))\n",
    "\n",
    "#             elif reranker_type == 'cross-encoder':\n",
    "#                 sentence_pairs = [[query_text, doc_text] for doc_text in doc_texts_for_scoring]\n",
    "#                 cross_scores = model.predict(sentence_pairs, show_progress_bar=False, batch_size=exp_config['batch_size'], convert_to_numpy=True)\n",
    "#                 doc_scores_calculated = dict(zip(valid_doc_ids, cross_scores))\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"\\nError during scoring query {query_id} in exp {exp_config.get('exp_id', 'N/A')}: {type(e).__name__} - {e}\")\n",
    "#             results[query_id] = candidate_doc_ids; continue\n",
    "\n",
    "#         # --- Rank Documents ---\n",
    "#         min_score = min(doc_scores_calculated.values()) if doc_scores_calculated else 0\n",
    "#         fallback_score = min_score - 1 if min_score > -float('inf') else -float('inf')\n",
    "#         scored_doc_list = []\n",
    "#         processed_docs = set()\n",
    "#         for doc_id, score in doc_scores_calculated.items():\n",
    "#             scored_doc_list.append((doc_id, float(score)))\n",
    "#             processed_docs.add(doc_id)\n",
    "#         for doc_id in candidate_doc_ids:\n",
    "#             if doc_id not in processed_docs: scored_doc_list.append((doc_id, fallback_score))\n",
    "#         scored_doc_list.sort(key=lambda x: x[1], reverse=True)\n",
    "#         final_ranked_list = [doc_id for doc_id, score in scored_doc_list]\n",
    "#         results[query_id] = final_ranked_list[:len(candidate_doc_ids)]\n",
    "\n",
    "#     del model\n",
    "#     if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Files Loaded**\n",
    "- `query_list_file`: List of query IDs.\n",
    "- `pre_ranking_file`: Initial candidate document rankings per query.\n",
    "- `queries_content_file`: Dictionary of query text content.\n",
    "- `documents_content_file`: Dictionary of document text content.\n",
    "- Ensures all IDs and keys are cast to strings for consistency.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Data Validation**\n",
    "- Ensures all required datasets (`query_ids`, `pre_ranking_data`, `queries_content`, `documents_content`) are loaded successfully.\n",
    "- Exits early with a warning if any are missing.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Running Experiments**\n",
    "- Iterates over all experiment configurations in `experiments`.\n",
    "- For each experiment:\n",
    "  1. **Preparation**:\n",
    "     - Merges base config with experiment-specific overrides (`exp_id`, model name, text type).\n",
    "  2. **Reranking**:\n",
    "     - Calls `perform_reranking()` to generate final document rankings per query.\n",
    "  3. **Timing**:\n",
    "     - Measures and prints duration of each experiment.\n",
    "  4. **Output Saving**:\n",
    "     - Saves predictions to a JSON file if `save_individual_predictions` is `True`.\n",
    "     - File name format: `prediction_exp_<exp_id>.json`.\n",
    "\n",
    "---\n",
    "\n",
    "This section automates the full reranking and prediction pipeline for multiple experiment configurations, outputting prediction files ready for downstream evaluation or submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Base device requested: {config.get('device', 'None specified')}\")\n",
    "# print(f\"Using effective device: {config['device']}\") # Show auto-detected device\n",
    "\n",
    "# # --- Construct Full Paths ---\n",
    "# def get_full_path(path): return path if os.path.isabs(path) else os.path.join(config['base_dir'], path)\n",
    "# query_list_file = get_full_path(config['query_list_file'])\n",
    "# pre_ranking_file = get_full_path(config['pre_ranking_file'])\n",
    "# queries_content_file = get_full_path(config['queries_content_file'])\n",
    "# documents_content_file = get_full_path(config['documents_content_file'])\n",
    "\n",
    "# print(\"\\nLoading shared data...\")\n",
    "# query_ids_raw = load_json_file(query_list_file)\n",
    "# pre_ranking_data_raw = load_json_file(pre_ranking_file)\n",
    "# queries_content_raw = load_content_data(queries_content_file)\n",
    "# documents_content_raw = load_content_data(documents_content_file)\n",
    "\n",
    "# if query_ids_raw is None: print(\"\\nError: Failed to load query_list_file. Exiting.\");\n",
    "# query_ids = [str(qid) for qid in query_ids_raw]\n",
    "# print(f\"Loaded and processed {len(query_ids)} query IDs (as strings).\")\n",
    "\n",
    "# if pre_ranking_data_raw is None: print(\"\\nError: Failed to load pre_ranking_file. Exiting.\");\n",
    "# pre_ranking_data = {str(k): list(map(str, v)) for k, v in pre_ranking_data_raw.items()}\n",
    "# print(f\"Processed {len(pre_ranking_data)} pre-ranking entries (keys/docs as strings).\")\n",
    "\n",
    "# if queries_content_raw is None or documents_content_raw is None:\n",
    "#         print(\"\\nError: Failed to load content files. Exiting.\");\n",
    "# queries_content = {str(k): v for k, v in queries_content_raw.items()}\n",
    "# documents_content = {str(k): v for k, v in documents_content_raw.items()}\n",
    "# print(\"Ensured content dictionary keys are strings.\")\n",
    "# # ------------------------------------\n",
    "\n",
    "# if not all([pre_ranking_data, queries_content, documents_content]):\n",
    "#     print(\"\\nError: Failed to load one or more data files (pre-ranking, content). Exiting.\")\n",
    "\n",
    "# print(f\"\\nStarting {len(experiments)} experiments to generate prediction files...\")\n",
    "\n",
    "# for i, exp_params in enumerate(experiments):\n",
    "#     exp_id = exp_params.get('exp_id', f'exp_{i+1}')\n",
    "#     print(f\"\\n--- Running Experiment: {exp_id} ---\")\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     run_config = config.copy()\n",
    "#     run_config.update(exp_params)\n",
    "\n",
    "#     # Perform re-ranking\n",
    "#     predictions = perform_reranking(\n",
    "#         run_config,\n",
    "#         query_ids,\n",
    "#         pre_ranking_data,\n",
    "#         queries_content,\n",
    "#         documents_content\n",
    "#     )\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     elapsed_time = end_time - start_time\n",
    "#     print(f\"Experiment {exp_id} finished in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "#     if predictions is None:\n",
    "#         print(f\"Experiment {exp_id} failed during re-ranking. No prediction file generated.\")\n",
    "#     else:\n",
    "#         # Save predictions if enabled\n",
    "#         if run_config.get('save_individual_predictions', False):\n",
    "#                 pred_filename = f\"{run_config.get('output_file_prefix', 'pred')}_{exp_id}.json\"\n",
    "#                 pred_filepath = get_full_path(pred_filename)\n",
    "#                 save_json_file(predictions, pred_filepath) # Save the generated predictions\n",
    "#         else:\n",
    "#                 print(f\"Skipping saving prediction file for {exp_id} as 'save_individual_predictions' is False.\")\n",
    "\n",
    "# print(\"\\nAll experiments complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
